"""
VLM Navigation Controller
=========================
åŸºäºVLMçš„è‡ªåŠ¨å¯¼èˆªæ§åˆ¶å™¨

ç»§æ‰¿InteractiveNavigationControllerçš„æ ¸å¿ƒåŠŸèƒ½ï¼š
- è¯­ä¹‰å»ºå›¾ï¼ˆGroundedSAM + Semantic Mappingï¼‰
- å¯è§†åŒ–ï¼ˆMapVisualizerï¼‰
- 12æ­¥Ã—30Â°ç¯è§†å»ºå›¾

æ–°å¢VLMåŠŸèƒ½ï¼š
- LLMé«˜å±‚è§„åˆ’ï¼ˆç”Ÿæˆå­ä»»åŠ¡ï¼‰
- VLMä½å±‚åŠ¨ä½œæ‰§è¡Œï¼ˆåŸºäºRGB+åœ°å›¾å†³ç­–ï¼‰
- 4æ–¹å‘è§‚å¯Ÿæ”¶é›†ï¼ˆå‰/å³/å/å·¦ï¼‰
- RGB+ä¿¯è§†å›¾æ‹¼æ¥å¯è§†åŒ–ï¼ˆä½¿ç”¨ç¯å¢ƒæä¾›çš„top_down_map_vlnceï¼‰
- ç»“æœä¿å­˜ä¾›åç»­æµ‹è¯„
"""
import os
import cv2
import json
import numpy as np
import torch
from typing import Dict, Any, List, Tuple, Optional
from datetime import datetime

from habitat import Config
from habitat.sims.habitat_simulator.actions import HabitatSimActions

from vlnce_baselines.interactive_navigation_controller import InteractiveNavigationController
from vlnce_baselines.vlm import LLMPlanner, ActionExecutor, ObservationCollector


class VLMNavigationController(InteractiveNavigationController):
    """
    VLMå¯¼èˆªæ§åˆ¶å™¨
    
    ç»§æ‰¿è‡ªInteractiveNavigationControllerï¼Œæ·»åŠ VLMè§„åˆ’å’Œæ‰§è¡ŒåŠŸèƒ½
    
    å·¥ä½œæµç¨‹ï¼š
    1. åˆå§‹ç¯è§†å»ºå›¾ï¼ˆ12æ­¥Ã—30Â°ï¼‰â†’ æ”¶é›†4æ–¹å‘å›¾åƒ
    2. LLMè§„åˆ’ â†’ ç”Ÿæˆåˆå§‹å­ä»»åŠ¡
    3. VLMæ‰§è¡Œ â†’ å¾ªç¯æ‰§è¡ŒåŠ¨ä½œç›´åˆ°å­ä»»åŠ¡å®Œæˆ
    4. éªŒè¯ç¯è§†å»ºå›¾ï¼ˆ12æ­¥Ã—30Â°ï¼‰â†’ æ›´æ–°åœ°å›¾å’Œ4æ–¹å‘å›¾åƒ
    5. éªŒè¯é‡è§„åˆ’ â†’ æ£€æŸ¥å®ŒæˆçŠ¶æ€ï¼Œç”Ÿæˆä¸‹ä¸€å­ä»»åŠ¡
    6. é‡å¤3-5ç›´åˆ°å¯¼èˆªå®Œæˆ
    
    æ³¨æ„ï¼šæ¯æ¬¡éªŒè¯é‡è§„åˆ’å‰éƒ½ä¼šæ‰§è¡Œ360Â°ç¯è§†ï¼Œä»¥æ›´æ–°è¯­ä¹‰åœ°å›¾å’Œå½“å‰ä½ç½®çš„4æ–¹å‘è§‚å¯Ÿ
    """
    
    # 4æ–¹å‘é…ç½®ï¼ˆä»ç¯è§†ä¸­æå–ï¼‰
    # ç¯è§†æ˜¯é€†æ—¶é’ˆTURN_LEFTï¼Œ12æ­¥Ã—30Â°=360Â°
    DIRECTION_STEPS = [0, 3, 6, 9]  # å¯¹åº”12æ­¥ä¸­çš„ç¥°0,3,6,9æ­¥
    DIRECTION_NAMES = [
        "Front (0Â°)",      # æ­¥éª¤0: åˆå§‹æœå‘
        "Left (90Â°)",      # æ­¥éª¤3: å·¦è½¬90Â°
        "Back (180Â°)",     # æ­¥éª¤6: åæ–¹
        "Right (270Â°)"     # æ­¥éª¤9: å³æ–¹ï¼ˆæˆ–å·¦è½¬270Â°ï¼‰
    ]
    
    # åŠ¨ä½œæ˜ å°„ï¼ˆä¸interactive_navigationä¸€è‡´ï¼‰
    ACTION_MAPPING = {
        "STOP": 0,
        "MOVE_FORWARD": 1, 
        "TURN_LEFT": 2,
        "TURN_RIGHT": 3
    }
    
    def __init__(self, config: Config,
                 llm_config_path: str = "vlnce_baselines/vlm/llm_config.yaml",
                 vlm_config_path: str = "vlnce_baselines/vlm/vlm_config.yaml"):
        """
        åˆå§‹åŒ–VLMå¯¼èˆªæ§åˆ¶å™¨
        
        Args:
            config: Habitaté…ç½®
            llm_config_path: LLMé…ç½®æ–‡ä»¶è·¯å¾„
            vlm_config_path: VLMé…ç½®æ–‡ä»¶è·¯å¾„
        """
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–ï¼ˆåˆå§‹åŒ–ç¯å¢ƒã€æ£€æµ‹ã€å»ºå›¾ã€å¯è§†åŒ–ï¼‰
        super().__init__(config)
        
        # åˆå§‹åŒ–VLMæ¨¡å—
        print("\n[Init] åˆå§‹åŒ–VLMæ¨¡å—...")
        
        # è·å–åŠ¨ä½œå‚æ•°
        self.turn_angle = config.TASK_CONFIG.SIMULATOR.TURN_ANGLE  # 30Â°
        self.move_distance = config.TASK_CONFIG.SIMULATOR.FORWARD_STEP_SIZE  # 0.25m
        
        # åŠ¨ä½œç©ºé—´æè¿°
        self.action_space = f"MOVE_FORWARD ({self.move_distance}m), TURN_LEFT ({self.turn_angle}Â°), TURN_RIGHT ({self.turn_angle}Â°), STOP"
        
        # åˆå§‹åŒ–LLMè§„åˆ’å™¨
        try:
            self.planner = LLMPlanner(llm_config_path, self.action_space)
        except Exception as e:
            print(f"âš ï¸  LLM Planneråˆå§‹åŒ–å¤±è´¥: {e}")
            self.planner = None
        
        # åˆå§‹åŒ–VLMæ‰§è¡Œå™¨
        try:
            self.action_executor = ActionExecutor(vlm_config_path, self.turn_angle, self.move_distance)
        except Exception as e:
            print(f"âš ï¸  Action Executoråˆå§‹åŒ–å¤±è´¥: {e}")
            self.action_executor = None
        
        # VLMçŠ¶æ€
        self.current_subtask = None
        self.subtask_count = 0
        self.progress_summary = ""
        self.subtask_history = []
        self.current_subtask_file = None  # å½“å‰å­ä»»åŠ¡æ–‡ä»¶è·¯å¾„
        
        # ç©ºé—´è®°å¿†ç³»ç»Ÿï¼ˆWaypoint Memoryï¼‰
        self.waypoint_memory = []  # è·¯å¾„ç‚¹åˆ—è¡¨ [{id, position, area_name, description, step, detected_objects}]
        self.waypoint_counter = 0   # è·¯å¾„ç‚¹è®¡æ•°å™¨
        
        # è§‚å¯Ÿç¼“å­˜
        self.latest_obs = None  # ç¼“å­˜æœ€æ–°çš„è§‚å¯Ÿ
        self.latest_info = None  # ç¼“å­˜æœ€æ–°çš„infoï¼ˆåŒ…å«top_down_map_vlnceï¼‰
        
        # è§‚å¯Ÿç¼“å­˜ï¼ˆç¯è§†æ—¶æ”¶é›†çš„4æ–¹å‘å›¾åƒï¼‰
        self.direction_images = {}  # {direction_name: image_path}
        self.latest_map_image = None
        
        # ObservationCollectorï¼ˆç”¨äºRGB+ä¿¯è§†å›¾æ‹¼æ¥å’ŒGIFç”Ÿæˆï¼‰
        self.obs_collector = None
        
        print("[Init] VLMæ¨¡å—åˆå§‹åŒ–å®Œæˆ\n")
    
    def reset_episode(self, episode_id: int = None):
        """é‡ç½®Episodeï¼ŒåŒ…æ‹¬VLMçŠ¶æ€"""
        # è°ƒç”¨çˆ¶ç±»é‡ç½®
        super().reset_episode(episode_id)
        
        # é‡ç½®VLMçŠ¶æ€
        self.current_subtask = None
        self.subtask_count = 0
        self.progress_summary = ""
        self.subtask_history = []
        self.current_subtask_file = None
        self.direction_images = {}
        self.latest_map_image = None
        
        # é‡ç½®ç©ºé—´è®°å¿†
        self.waypoint_memory = []
        self.waypoint_counter = 0
        
        # åˆ›å»ºVLMä¸“ç”¨ç›®å½•
        self.vlm_dir = os.path.join(
            self.config.RESULTS_DIR, 
            f'episode_{self.current_episode_id}',
            'vlm'
        )
        os.makedirs(self.vlm_dir, exist_ok=True)
        os.makedirs(os.path.join(self.vlm_dir, 'observations'), exist_ok=True)
        os.makedirs(os.path.join(self.vlm_dir, 'subtasks'), exist_ok=True)
        
        # åˆå§‹åŒ–ObservationCollectorï¼ˆç”¨äºRGB+ä¿¯è§†å›¾æ‹¼æ¥ï¼‰
        self.obs_collector = ObservationCollector(os.path.join(self.vlm_dir, 'observations'))
        self.obs_collector.setup_maps_dir(self.vlm_dir)
    
    def look_around_and_collect(self) -> Tuple[List[str], List[str]]:
        """
        360Â°ç¯è§†å»ºå›¾ + æ”¶é›†4æ–¹å‘è§‚å¯Ÿå›¾åƒ
        
        æ‰§è¡Œ12æ­¥Ã—30Â°é€†æ—¶é’ˆæ—‹è½¬ï¼ˆTURN_LEFTï¼‰å»ºå›¾ï¼ŒåŒæ—¶æ”¶é›†4æ–¹å‘å›¾åƒï¼š
        - æ­¥éª¤0: å‰ (0Â°)
        - æ­¥éª¤3: å·¦ (90Â°)
        - æ­¥éª¤6: å (180Â°)
        - æ­¥éª¤9: å³ (270Â°)
        
        Returns:
            (image_paths, direction_names) - 4æ–¹å‘å›¾åƒè·¯å¾„å’Œåç§°
        """
        print("\n" + "="*60)
        print("ğŸ”„ ç¯è§†æ‰«æ + æ”¶é›†4æ–¹å‘è§‚å¯Ÿ (360Â°)")
        print("="*60)
        
        collected_images = []
        collected_directions = []
        
        # æ‰§è¡Œ12æ¬¡æ—‹è½¬ (step-0 åˆ° step-11)
        from habitat.sims.habitat_simulator.actions import HabitatSimActions
        for step in range(12):
            # æ‰§è¡Œæ—‹è½¬
            actions = [{"action": HabitatSimActions.TURN_LEFT}]
            outputs = self.envs.step(actions)
            obs, _, dones, _ = [list(x) for x in zip(*outputs)]
            
            if dones[0]:
                print("âš ï¸ Episodeæå‰ç»“æŸ")
                break
            
            # æ›´æ–°æ£€æµ‹å’Œå»ºå›¾
            prev_class_count = len(self.detected_classes)
            batch_obs = self._batch_obs(obs, save_object_detection=True, step=step)
            poses = torch.from_numpy(np.array([item['sensor_pose'] for item in obs])).float().to(self.device)
            
            map_state = self.mapper.update_map(
                batch_obs, poses, step,
                list(self.detected_classes), self.current_episode_id
            )
            
            new_classes = len(self.detected_classes) - prev_class_count
            
            # ä¿å­˜å¯è§†åŒ–
            rgb_bgr = cv2.cvtColor(obs[0]['rgb'], cv2.COLOR_RGB2BGR)
            _, landmarks = self.visualizer.save_step_visualization(
                step=step,
                episode_id=self.current_episode_id,
                rgb=rgb_bgr,
                full_map=map_state['full_map'],
                trajectory_points=map_state['trajectory_points'],
                detected_classes=list(self.detected_classes),
                current_pose=map_state['full_pose'],
                floor=map_state['floor'],
                hfov=self.config.MAP.HFOV,
                detections=self.latest_detections_full if hasattr(self, 'latest_detections_full') else None,
                labels=self.latest_labels_full if hasattr(self, 'latest_labels_full') else None,
                landmark_classes=self.landmark_classes,
                mapping_classes=self.mapping_classes,
                landmark_config={
                    'min_total_pixels': self.landmark_min_total_pixels,
                    'min_area_threshold': self.landmark_min_area_threshold
                }
            )
            
            # æ”¶é›†4æ–¹å‘å›¾åƒï¼ˆæ­¥éª¤0,3,6,9 å¯¹åº” å‰,å³,å,å·¦ï¼‰
            if step in self.DIRECTION_STEPS:
                direction_idx = self.DIRECTION_STEPS.index(step)
                direction_name = self.DIRECTION_NAMES[direction_idx]
                
                # ä¿å­˜æ–¹å‘è§‚å¯Ÿå›¾åƒ
                img_path = os.path.join(
                    self.vlm_dir, 'observations',
                    f'lookaround_dir{direction_idx}_{direction_name.split()[0].lower()}.jpg'
                )
                cv2.imwrite(img_path, rgb_bgr)
                
                collected_images.append(img_path)
                collected_directions.append(direction_name)
                self.direction_images[direction_name] = img_path
                
                print(f"  ğŸ“· [{step+1}/12] æ”¶é›† {direction_name}" + (f" +{new_classes}ç±»" if new_classes > 0 else ""))
            else:
                if new_classes > 0:
                    print(f"  [{step+1}/12] +{new_classes}ç±»")
            
            # ç¼“å­˜æœ€åä¸€æ­¥çš„è§‚å¯Ÿ
            self.latest_obs = obs[0]
        
        # å®Œæˆ12æ¬¡æ—‹è½¬ï¼Œä¿å­˜äº† step-0 åˆ° step-11ï¼ˆå…±12å¼ ï¼‰
        # è®¾ç½® current_step = 12ï¼Œè¡¨ç¤ºä¸‹æ¬¡åŠ¨ä½œå°†ä¿å­˜ä¸º step-12
        self.current_step = 12
        
        # è·å–æœ€æ–°åœ°å›¾è·¯å¾„ï¼ˆglobal_map/ä¸­çš„å›¾åƒç”±çˆ¶ç±»save_step_visualizationä¿å­˜ï¼‰
        self._get_current_map_path()
        
        print("="*60)
        print(f"âœ… å®Œæˆ | {len(self.detected_classes)}ç±» | {len(collected_images)}æ–¹å‘å›¾åƒ")
        print(f"   ä¿å­˜æ–‡ä»¶: step-0 åˆ° step-12 (å…±13å¼ )")
        print("="*60 + "\n")
        
        return collected_images, collected_directions
    
    def _get_current_map_path(self) -> str:
        """
        è·å–å½“å‰è¯­ä¹‰åœ°å›¾è·¯å¾„ï¼ˆä½¿ç”¨global_map/ç›®å½•ä¸­çš„å›¾åƒï¼Œé¿å…é‡å¤ä¿å­˜ï¼‰
        
        Returns:
            global_mapç›®å½•ä¸­ä¸Šä¸€æ­¥ä¿å­˜çš„åœ°å›¾è·¯å¾„
        """
        # è¿”å›ä¸Šä¸€æ­¥ä¿å­˜çš„åœ°å›¾ï¼ˆå½“å‰æ­¥çš„åœ°å›¾è¦ç­‰step()æ‰§è¡Œåæ‰ä¼šä¿å­˜ï¼‰
        episode_dir = os.path.join(
            self.config.RESULTS_DIR, 
            f'episode_{self.current_episode_id}'
        )
        last_step = self.current_step - 1
        map_path = os.path.join(episode_dir, 'global_map', f'step-{last_step}.png')
        self.latest_map_image = map_path
        return map_path

    def get_4_direction_images_from_cache(self, phase: str = "initial") -> Tuple[List[str], List[str]]:
        """
        ä»ç¼“å­˜ä¸­è·å–4æ–¹å‘å›¾åƒ
        
        æ³¨æ„ï¼šæ­¤æ–¹æ³•ä»…åœ¨generate_initial_subtaskä¸­ä½¿ç”¨ï¼Œå› ä¸ºåˆå§‹è§„åˆ’å‰å·²ç»æ‰§è¡Œè¿‡ç¯è§†
        éªŒè¯é‡è§„åˆ’æ—¶ä¼šé‡æ–°æ‰§è¡Œlook_around_and_collect()æ¥æ›´æ–°åœ°å›¾å’Œ4æ–¹å‘å›¾åƒ
        
        Args:
            phase: é˜¶æ®µåç§°ï¼ˆç”¨äºæ–‡ä»¶å‘½åï¼‰
            
        Returns:
            (image_paths, direction_names) - 4æ–¹å‘å›¾åƒè·¯å¾„å’Œåç§°
        """
        print(f"\nğŸ“· è·å–4æ–¹å‘è§‚å¯Ÿå›¾åƒ ({phase})...")
        
        collected_images = []
        collected_directions = []
        
        # ä½¿ç”¨ç¯è§†æ—¶å·²ç»ä¿å­˜çš„å›¾åƒ
        for direction_name in self.DIRECTION_NAMES:
            if direction_name in self.direction_images:
                collected_images.append(self.direction_images[direction_name])
                collected_directions.append(direction_name)
                print(f"  âœ… {direction_name}")
            else:
                print(f"  âš ï¸ {direction_name} å›¾åƒæœªæ‰¾åˆ°")
        
        return collected_images, collected_directions
    
    def generate_initial_subtask(self) -> Optional[Dict]:
        """
        ç”Ÿæˆåˆå§‹å­ä»»åŠ¡
        
        ä½¿ç”¨ç¯è§†æ”¶é›†çš„4æ–¹å‘å›¾åƒ + å…¨å±€åœ°å›¾ + å±€éƒ¨åœ°å›¾è°ƒç”¨LLMç”Ÿæˆå­ä»»åŠ¡
        """
        if not self.planner:
            print("âœ— LLM Planneræœªåˆå§‹åŒ–")
            return None
        
        print(f"\n{'*'*60}")
        print("ğŸ¤– ç”Ÿæˆåˆå§‹å­ä»»åŠ¡")
        print(f"{'*'*60}")
        
        # ä½¿ç”¨ç¯è§†æ—¶å·²ç»æ”¶é›†çš„å›¾åƒï¼ˆé¿å…é‡å¤æ—‹è½¬ï¼‰
        image_paths, direction_names = self.get_4_direction_images_from_cache("initial")
        
        # è·å–åœ°å›¾è·¯å¾„
        # æ³¨æ„ï¼šç¯è§†å current_step=12ï¼Œæœ€åä¿å­˜çš„åœ°å›¾æ˜¯ step-11
        episode_dir = os.path.join(
            self.config.RESULTS_DIR, 
            f'episode_{self.current_episode_id}'
        )
        last_saved_step = self.current_step - 1  # 11
        global_map = os.path.join(episode_dir, 'global_map', f'step-{last_saved_step}.png')
        local_map = os.path.join(episode_dir, 'local_map', f'step-{last_saved_step}.png')
        
        # éªŒè¯åœ°å›¾æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(global_map):
            print(f"âœ— Global map not found: {global_map}")
            return None
        
        # åˆ›å»ºå¸¦waypointæ ‡æ³¨çš„åœ°å›¾å‰¯æœ¬ï¼ˆä¸è¦†ç›–åŸå§‹åœ°å›¾ï¼‰
        global_map_for_llm = global_map
        if len(self.waypoint_memory) > 0:
            global_map_img = cv2.imread(global_map)
            global_map_img = self.visualize_waypoints_on_map(global_map_img)
            # ä¿å­˜ä¸ºå•ç‹¬çš„å¯è§†åŒ–ç‰ˆæœ¬
            global_map_for_llm = os.path.join(episode_dir, 'global_map', f'step-{self.current_step}_with_waypoints.png')
            cv2.imwrite(global_map_for_llm, global_map_img)
        
        # è°ƒç”¨LLMç”Ÿæˆåˆå§‹å­ä»»åŠ¡ï¼ˆç¬¬ä¸€æ¬¡è§„åˆ’ï¼Œæ— detected_landmarkså’Œwaypoint_summaryï¼‰
        response = self.planner.generate_initial_subtask(
            instruction=self.current_instruction,
            observation_images=image_paths,
            direction_names=direction_names,
            global_map_image=global_map_for_llm,  # ä½¿ç”¨å¸¦waypointæ ‡æ³¨çš„ç‰ˆæœ¬
            local_map_image=local_map if os.path.exists(local_map) else None
        )
        
        if not response:
            print("âœ— LLMæœªè¿”å›æœ‰æ•ˆå“åº”")
            return None
        
        # ä¿å­˜å­ä»»åŠ¡
        self.current_subtask = response
        self.subtask_count += 1
        self.progress_summary = ""
        
        # è®°å½•å½“å‰ä½ç½®ä¿¡æ¯ï¼ˆç”¨äºåç»­éªŒè¯å‚è€ƒï¼‰
        self.current_position_info = {
            'waypoint': response.get('waypoint', 'Unknown'),
            'observation': response.get('current_observation', ''),
            'step': self.current_step
        }
        
        # åˆ›å»ºè·¯å¾„ç‚¹è®°å½•ï¼ˆç©ºé—´è®°å¿†ï¼‰
        waypoint_desc = response.get('waypoint', 'Unknown location')
        # ä¸ä¼ positionå‚æ•°ï¼Œè®©add_waypoint()ä»mapper.curr_locè·å–æ­£ç¡®çš„åœ°å›¾åƒç´ åæ ‡
        self.add_waypoint(waypoint_desc)
        
        # è®°å½•å¹¶åŠ¨æ€æ›´æ–°ç›®æ ‡landmark
        subtask_landmark = response.get('subtask_landmark', None)
        if subtask_landmark:
            # éªŒè¯ï¼šåªè¦åœ¨mapping_classesä¸­ï¼ˆèƒ½è¢«GroundedSAMæ£€æµ‹ï¼‰å°±å¯ä»¥ä½œä¸ºlandmark
            if subtask_landmark in self.mapping_classes:
                # åŠ¨æ€æ›´æ–°landmark_classesï¼ˆåªæ ‡æ³¨å½“å‰å­ä»»åŠ¡çš„ç›®æ ‡ï¼‰
                self.landmark_classes = [subtask_landmark]
                self.target_landmark = subtask_landmark
                print(f"  ğŸ¯ ç›®æ ‡Landmarkå·²è®¾å®š: {self.target_landmark}")
                print(f"  ğŸ“ å·²åŠ¨æ€æ›´æ–°landmark_classes: {self.landmark_classes}")
            else:
                print(f"  âš ï¸  è­¦å‘Š: '{subtask_landmark}' ä¸åœ¨mapping_classesä¸­ï¼ŒGroundedSAMæ— æ³•æ£€æµ‹")
                print(f"  ğŸ’¡ å¯æ£€æµ‹ç±»åˆ«: {', '.join(self.mapping_classes)}")
                self.target_landmark = None
                self.landmark_classes = []  # é‡ç½®ä¸ºç©º
        else:
            print(f"  â„¹ï¸  æœªæŒ‡å®šsubtask_landmarkï¼Œä¸æ ‡æ³¨landmark")
            self.target_landmark = None
            self.landmark_classes = []  # é‡ç½®ä¸ºç©º
        
        self._save_subtask(response, "initial")
        
        # æ‰“å°å­ä»»åŠ¡ä¿¡æ¯
        self._print_subtask_info(response, is_initial=True)
        
        return response
    
    def verify_and_replan(self) -> Tuple[bool, Optional[Dict]]:
        """
        éªŒè¯å½“å‰å­ä»»åŠ¡å¹¶é‡æ–°è§„åˆ’
        
        æµç¨‹ï¼š
        1. æ‰§è¡Œ360Â°ç¯è§†å»ºå›¾ï¼ˆæ›´æ–°è¯­ä¹‰åœ°å›¾ï¼‰
        2. æ”¶é›†å½“å‰ä½ç½®çš„4æ–¹å‘å›¾åƒ
        3. è°ƒç”¨LLMéªŒè¯å­ä»»åŠ¡å®ŒæˆçŠ¶æ€
        4. å¦‚æœªå®Œæˆï¼Œç”Ÿæˆæ–°å­ä»»åŠ¡
        
        Returns:
            (is_completed, new_subtask)
        """
        if not self.planner or not self.current_subtask:
            return False, None
        
        # è·å–ç¯è§†æ—¶æ”¶é›†çš„4æ–¹å‘å›¾åƒ
        phase = f"verify_{self.subtask_count}"
        image_paths, direction_names = self.get_4_direction_images_from_cache(phase)
        
        if not image_paths:
            print("âœ— ç¯è§†å»ºå›¾å¤±è´¥")
            return False, None
        
        # è·å–åœ°å›¾è·¯å¾„
        # éªŒè¯æ—¶åˆšå®Œæˆ 360Â° æ‰«æï¼Œcurrent_step å·²é€’å¢ï¼Œéœ€è¦ä½¿ç”¨ä¸Šä¸€æ­¥çš„åœ°å›¾
        episode_dir = os.path.join(
            self.config.RESULTS_DIR, 
            f'episode_{self.current_episode_id}'
        )
        last_saved_step = self.current_step - 1
        global_map = os.path.join(episode_dir, 'global_map', f'step-{last_saved_step}.png')
        local_map = os.path.join(episode_dir, 'local_map', f'step-{last_saved_step}.png')
        
        # éªŒè¯åœ°å›¾æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(global_map):
            print(f"âœ— Global map not found: {global_map}")
            return False, None
        
        # åˆ›å»ºå¸¦waypointæ ‡æ³¨çš„åœ°å›¾å‰¯æœ¬ï¼ˆä¸è¦†ç›–åŸå§‹åœ°å›¾ï¼‰
        global_map_for_llm = global_map
        if len(self.waypoint_memory) > 0:
            global_map_img = cv2.imread(global_map)
            global_map_img = self.visualize_waypoints_on_map(global_map_img)
            # ä¿å­˜ä¸ºå•ç‹¬çš„å¯è§†åŒ–ç‰ˆæœ¬
            global_map_for_llm = os.path.join(episode_dir, 'global_map', f'step-{last_saved_step}_with_waypoints.png')
            cv2.imwrite(global_map_for_llm, global_map_img)
        
        # è·å–å·²æ£€æµ‹åˆ°çš„landmarkç±»åˆ«
        detected_landmarks = list(self.detected_classes) if hasattr(self, 'detected_classes') else []
        
        # è·å–è·¯å¾„ç‚¹å†å²è®°å½•
        waypoint_summary = self.get_waypoint_summary()
        
        # è°ƒç”¨LLMéªŒè¯ï¼ˆå…¨å±€åœ°å›¾å¿…éœ€ï¼Œå±€éƒ¨åœ°å›¾å¯é€‰ï¼Œä¼ é€’å®é™…æ£€æµ‹åˆ°çš„ç±»åˆ«ï¼‰
        response, is_completed = self.planner.verify_and_replan(
            instruction=self.current_instruction,
            current_subtask=self.current_subtask,
            observation_images=image_paths,
            direction_names=direction_names,
            global_map_image=global_map_for_llm,  # ä½¿ç”¨å¸¦waypointæ ‡æ³¨çš„ç‰ˆæœ¬
            local_map_image=local_map if os.path.exists(local_map) else None,
            detected_landmarks=detected_landmarks,
            waypoint_summary=waypoint_summary
        )
        
        print(f"  ğŸ·ï¸  Detected landmarks: {detected_landmarks if detected_landmarks else 'None'}")
        
        if not response:
            print("âœ— LLMéªŒè¯æœªè¿”å›æœ‰æ•ˆå“åº”")
            return False, None
        
        if is_completed:
            print(f"\nâœ… å­ä»»åŠ¡ #{self.subtask_count} å®Œæˆ!")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆå­ä»»åŠ¡
            if response.get('is_final_subtask', False):
                print("ğŸ¯ åˆ°è¾¾æœ€ç»ˆç›®çš„åœ°!")
                return True, response
            
            # æ¸…ç©ºä¸Šä¸€ä¸ªå­ä»»åŠ¡çš„è½¨è¿¹ï¼ˆæ¯ä¸ªå­ä»»åŠ¡ç‹¬ç«‹æ˜¾ç¤ºï¼‰
            print("  ğŸ§¹ æ¸…ç©ºä¸Šä¸€å­ä»»åŠ¡è½¨è¿¹...")
            self.mapper.clear_trajectory()
            
            # æ›´æ–°åˆ°æ–°å­ä»»åŠ¡
            self.subtask_count += 1
            self.current_subtask = response
            self.progress_summary = ""
            
            # æ›´æ–°å½“å‰ä½ç½®ä¿¡æ¯ï¼ˆç”¨äºåç»­å‚è€ƒï¼‰
            self.current_position_info = {
                'waypoint': response.get('waypoint', 'Unknown'),
                'observation': response.get('current_observation', ''),
                'step': self.current_step
            }
            
            # åˆ›å»ºè·¯å¾„ç‚¹è®°å½•ï¼ˆç©ºé—´è®°å¿†ï¼‰
            waypoint_desc = response.get('waypoint', 'Unknown location')
            # ä¸ä¼ positionå‚æ•°ï¼Œè®©add_waypoint()ä»mapper.curr_locè·å–æ­£ç¡®çš„åœ°å›¾åƒç´ åæ ‡
            self.add_waypoint(waypoint_desc)
            
            # åŠ¨æ€æ›´æ–°ç›®æ ‡landmarkï¼ˆè‡ªåŠ¨æ›¿æ¢ä¸Šä¸€ä¸ªå­ä»»åŠ¡çš„landmarkï¼‰
            subtask_landmark = response.get('subtask_landmark', None)
            if subtask_landmark:
                # éªŒè¯ï¼šåªè¦åœ¨mapping_classesä¸­ï¼ˆèƒ½è¢«GroundedSAMæ£€æµ‹ï¼‰å°±å¯ä»¥ä½œä¸ºlandmark
                if subtask_landmark in self.mapping_classes:
                    # åŠ¨æ€æ›´æ–°landmark_classesï¼ˆåªæ ‡æ³¨å½“å‰å­ä»»åŠ¡çš„ç›®æ ‡ï¼‰
                    # æ³¨æ„ï¼šè¿™é‡Œæ›´æ–°ä¼šè‡ªåŠ¨æ›¿æ¢æ‰ä¸Šä¸€ä¸ªå­ä»»åŠ¡çš„landmarkæ ‡æ³¨
                    self.landmark_classes = [subtask_landmark]
                    self.target_landmark = subtask_landmark
                    print(f"  ğŸ¯ æ–°ç›®æ ‡Landmark: {self.target_landmark}")
                    print(f"  ğŸ“ å·²æ›´æ–°landmark_classes: {self.landmark_classes} (æ›¿æ¢ä¸Šä¸€å­ä»»åŠ¡)")
                else:
                    print(f"  âš ï¸  è­¦å‘Š: '{subtask_landmark}' ä¸åœ¨mapping_classesä¸­ï¼ŒGroundedSAMæ— æ³•æ£€æµ‹")
                    self.target_landmark = None
                    self.landmark_classes = []  # é‡ç½®ä¸ºç©º
            else:
                print(f"  â„¹ï¸  æœªæŒ‡å®šæ–°landmarkï¼Œä¸æ ‡æ³¨landmark")
                self.target_landmark = None
                self.landmark_classes = []  # é‡ç½®ä¸ºç©º
            
            self._save_subtask(response, f"subtask_{self.subtask_count}")
            self._print_subtask_info(response)
        else:
            print(f"\nğŸ”„ å­ä»»åŠ¡ #{self.subtask_count} æœªå®Œæˆï¼Œç»§ç»­...")
            
            # å³ä½¿æœªå®Œæˆä¹Ÿæ›´æ–°ä½ç½®è§‚å¯Ÿï¼ˆç”¨äºè®°å½•è½¨è¿¹ï¼‰
            if 'current_observation' in response:
                self.current_position_info = {
                    'waypoint': response.get('waypoint', getattr(self, 'current_position_info', {}).get('waypoint', 'Unknown')),
                    'observation': response.get('current_observation', ''),
                    'step': self.current_step
                }
            self.current_subtask = response
            self._save_subtask(response, f"subtask_{self.subtask_count}_refined")
        
        return is_completed, response
    
    def execute_action_with_vlm(self) -> Tuple[Optional[int], Optional[str], bool]:
        """
        ä½¿ç”¨VLMå†³ç­–å¹¶æ‰§è¡ŒåŠ¨ä½œ
        
        Returns:
            (action_id, action_name, should_stop)
        """
        if not self.action_executor or not self.current_subtask:
            return None, None, True
        
        # è·å–å½“å‰è§‚å¯Ÿï¼šä½¿ç”¨ç¼“å­˜çš„è§‚å¯Ÿæˆ–é€šè¿‡æ—‹è½¬è·å–
        if self.latest_obs is not None:
            obs = self.latest_obs
        else:
            # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œæ‰§è¡Œä¸€æ¬¡å³è½¬å†å·¦è½¬å›æ¥è·å–è§‚å¯Ÿ
            actions = [{"action": HabitatSimActions.TURN_RIGHT}]
            outputs = self.envs.step(actions)
            obs, _, dones, _ = [list(x) for x in zip(*outputs)]
            if dones[0]:
                print("âš ï¸ Episodeç»“æŸ")
                return None, None, True
            
            actions = [{"action": HabitatSimActions.TURN_LEFT}]
            outputs = self.envs.step(actions)
            obs, _, dones, _ = [list(x) for x in zip(*outputs)]
            if dones[0]:
                print("âš ï¸ Episodeç»“æŸ")
                return None, None, True
            obs = obs[0]
        
        # ä½¿ç”¨ä¸Šä¸€æ­¥ä¿å­˜çš„å›¾åƒï¼ˆå½“å‰æ­¥å›¾åƒè¦ç­‰step()æ‰§è¡Œåæ‰ä¼šä¿å­˜ï¼‰
        episode_dir = os.path.join(
            self.config.RESULTS_DIR, 
            f'episode_{self.current_episode_id}'
        )
        last_step = self.current_step - 1  # ä¸Šä¸€æ­¥å·²ä¿å­˜çš„æ–‡ä»¶
        fp_image = os.path.join(episode_dir, 'rgb', f'step-{last_step}.png')
        
        # å¦‚æœrgb/ä¸­çš„å›¾åƒè¿˜ä¸å­˜åœ¨ï¼Œç”¨å½“å‰è§‚å¯Ÿåˆ›å»ºä¸´æ—¶æ–‡ä»¶
        if not os.path.exists(fp_image):
            rgb_bgr = cv2.cvtColor(obs['rgb'], cv2.COLOR_RGB2BGR)
            temp_image = os.path.join(
                self.vlm_dir, 'observations',
                f'step{last_step}_first_person.jpg'
            )
            cv2.imwrite(temp_image, rgb_bgr)
            fp_image = temp_image
        
        # è·å–å½“å‰åœ°å›¾è·¯å¾„å’Œæ£€æµ‹å›¾åƒ
        self._get_current_map_path()
        
        # è·å–detectionå›¾åƒè·¯å¾„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        detection_image = os.path.join(episode_dir, 'detection', f'step-{last_step}.png')
        if not os.path.exists(detection_image):
            detection_image = None
        
        # è·å–å±€éƒ¨åœ°å›¾è·¯å¾„
        local_map = os.path.join(episode_dir, 'local_map', f'step-{last_step}.png')
        if not os.path.exists(local_map):
            local_map = None
        
        # è·å–å·²æ£€æµ‹çš„landmarkç±»åˆ«
        detected_landmarks = ', '.join(self.detected_classes) if hasattr(self, 'detected_classes') and self.detected_classes else None
        
        # è°ƒç”¨VLMå†³ç­–
        action_id, action_name, updated_progress, response = self.action_executor.decide_action(
            subtask_destination=self.current_subtask.get('subtask_destination', ''),
            subtask_instruction=self.current_subtask.get('subtask_instruction', ''),
            first_person_image=fp_image,
            action_mapping=self.ACTION_MAPPING,
            progress_summary=self.progress_summary,
            detection_image=detection_image,
            local_map_image=local_map,
            detected_landmarks=detected_landmarks
        )
        
        if action_id is None:
            print("âœ— VLMå†³ç­–å¤±è´¥")
            return None, None, True
        
        # æ›´æ–°è¿›åº¦
        self.progress_summary = updated_progress
        
        # æ£€æŸ¥æ˜¯å¦åœæ­¢
        should_stop = (action_name == "STOP")
        
        return action_id, action_name, should_stop
    
    def step_with_vlm(self, action: int, action_name: str = "", save_vis: bool = True) -> Dict[str, Any]:
        """
        æ‰§è¡ŒVLMå†³ç­–çš„åŠ¨ä½œï¼ˆè°ƒç”¨çˆ¶ç±»stepæ–¹æ³•ï¼‰å¹¶ç¼“å­˜è§‚å¯Ÿ
        
        Args:
            action: åŠ¨ä½œID
            action_name: åŠ¨ä½œåç§°ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
            save_vis: æ˜¯å¦ä¿å­˜å¯è§†åŒ–
            
        Returns:
            æ­¥éª¤ç»“æœå­—å…¸
        """
        result = self.step(action, save_vis)
        # ç¼“å­˜æœ€æ–°è§‚å¯Ÿå’Œinfoç”¨äºä¸‹æ¬¡VLMå†³ç­–å’Œå¯è§†åŒ–
        self.latest_obs = result.get('obs', None)
        self.latest_info = result.get('info', None)
        
        # ä¿å­˜RGB+ä¿¯è§†å›¾æ‹¼æ¥å¯è§†åŒ–ï¼ˆä½¿ç”¨ç¯å¢ƒæä¾›çš„top_down_map_vlnceï¼‰
        if save_vis and self.obs_collector and self.latest_obs is not None:
            subtask_text = None
            if self.current_subtask:
                subtask_text = self.current_subtask.get('subtask_instruction', '')
            
            distance = 0.0
            if self.latest_info:
                distance = self.latest_info.get('distance_to_goal', 0.0)
            
            self.obs_collector.save_step_visualization(
                observations=self.latest_obs,
                info=self.latest_info or {},
                step=self.current_step,
                instruction=self.current_instruction,
                current_subtask=subtask_text,
                distance=distance,
                action=action_name
            )
        
        return result
    
    def run_vlm_navigation(self, max_steps: int = 500, 
                          max_subtask_steps: int = 50,
                          verify_interval: int = 10) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„VLMå¯¼èˆªæµç¨‹
        
        Args:
            max_steps: æœ€å¤§æ€»æ­¥æ•°
            max_subtask_steps: æ¯ä¸ªå­ä»»åŠ¡æœ€å¤§æ­¥æ•°
            verify_interval: éªŒè¯é—´éš”æ­¥æ•°
            
        Returns:
            å¯¼èˆªç»“æœå­—å…¸
        """
        print("\n" + "="*60)
        print("ğŸš€ å¯åŠ¨VLMè‡ªåŠ¨å¯¼èˆª")
        print("="*60)
        print(f"ğŸ“ æŒ‡ä»¤: {self.current_instruction}")
        print(f"âš™ï¸  æœ€å¤§æ­¥æ•°: {max_steps} | å­ä»»åŠ¡æ­¥æ•°: {max_subtask_steps} | éªŒè¯é—´éš”: {verify_interval}")
        print("="*60 + "\n")
        
        # 1. ç¯è§†å»ºå›¾ + æ”¶é›†è§‚å¯Ÿ
        self.look_around_and_collect()
        
        # 2. ç”Ÿæˆåˆå§‹å­ä»»åŠ¡
        subtask = self.generate_initial_subtask()
        if not subtask:
            print("âœ— æ— æ³•ç”Ÿæˆåˆå§‹å­ä»»åŠ¡")
            return {
                'success': False,
                'total_steps': self.current_step,
                'subtask_count': 0,
                'detected_classes': list(self.detected_classes) if hasattr(self, 'detected_classes') else [],
                'gif_path': None,
                'result_file': None,
                'reason': 'initial_subtask_failed'
            }
        
        # 3. ä¸»å¯¼èˆªå¾ªç¯
        total_steps = self.current_step
        subtask_steps = 0
        navigation_complete = False
        
        while total_steps < max_steps:
            # VLMå†³ç­–åŠ¨ä½œ
            action_id, action_name, should_stop = self.execute_action_with_vlm()
            
            if action_id is None:
                print("âœ— VLMå†³ç­–å¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨è¾“å…¥...")
                action_id = self.get_keyboard_action()
                action_name = self._action_name(action_id)
                should_stop = (action_id == 0)
            
            # å¦‚æœVLMå†³å®šåœæ­¢ â†’ éªŒè¯å­ä»»åŠ¡
            if should_stop:
                is_completed, new_subtask = self.verify_and_replan()
                
                if is_completed and new_subtask and new_subtask.get('is_final_subtask', False):
                    print("\nğŸ¯ å¯¼èˆªå®Œæˆï¼")
                    navigation_complete = True
                    break
                
                subtask_steps = 0
                continue
            
            # æ‰§è¡ŒåŠ¨ä½œï¼ˆä¼ å…¥action_nameç”¨äºå¯è§†åŒ–ï¼‰
            result = self.step_with_vlm(action_id, action_name=action_name, save_vis=True)
            total_steps = self.current_step
            subtask_steps += 1
            
            print(f"[Step {total_steps}] {action_name} | å­ä»»åŠ¡æ­¥æ•°: {subtask_steps}")
            
            if result['done']:
                print("\nâœ… Episodeè‡ªåŠ¨å®Œæˆ")
                navigation_complete = True
                break
            
            # å®šæœŸéªŒè¯
            if subtask_steps >= verify_interval:
                is_completed, _ = self.verify_and_replan()
                if is_completed:
                    subtask_steps = 0
            
            # å­ä»»åŠ¡è¶…æ—¶
            if subtask_steps >= max_subtask_steps:
                print(f"\nâš ï¸ å­ä»»åŠ¡è¶…æ—¶ ({max_subtask_steps}æ­¥)ï¼Œé‡æ–°è§„åˆ’...")
                _, _ = self.verify_and_replan()
                subtask_steps = 0
        
        # 4. ä¿å­˜GIFåŠ¨ç”»
        gif_path = None
        if self.obs_collector:
            gif_path = self.obs_collector.save_gif(fps=2)
        
        # 5. ä¿å­˜ç»“æœï¼ˆä¾›åç»­æµ‹è¯„ï¼‰
        final_result = self._save_navigation_result(navigation_complete, total_steps)
        
        return {
            'success': navigation_complete,
            'total_steps': total_steps,
            'subtask_count': self.subtask_count,
            'detected_classes': list(self.detected_classes),
            'gif_path': gif_path,
            'result_file': final_result
        }
    
    def _save_subtask(self, subtask: Dict, name: str):
        """ä¿å­˜å­ä»»åŠ¡åˆ°æ–‡ä»¶"""
        filepath = os.path.join(self.vlm_dir, 'subtasks', f'{name}.json')
        
        data = {
            'episode_id': self.current_episode_id,
            'instruction': self.current_instruction,
            'subtask_id': self.subtask_count,
            'step': self.current_step,
            'timestamp': datetime.now().isoformat(),
            'subtask': subtask
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        self.subtask_history.append(data)
        self.current_subtask_file = filepath
    
    def _save_navigation_result(self, success: bool, total_steps: int) -> str:
        """
        ä¿å­˜å¯¼èˆªç»“æœï¼ˆä¾›åç»­æµ‹è¯„ï¼‰
        
        Args:
            success: æ˜¯å¦æˆåŠŸ
            total_steps: æ€»æ­¥æ•°
            
        Returns:
            ç»“æœæ–‡ä»¶è·¯å¾„
        """
        # å°è¯•è·å–è¯„æµ‹æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        metrics = {}
        if self.latest_info:
            metrics = {
                'distance_to_goal': self.latest_info.get('distance_to_goal', -1),
                'success': self.latest_info.get('success', success),
                'spl': self.latest_info.get('spl', 0.0),
                'path_length': self.latest_info.get('path_length', 0.0),
                'oracle_success': self.latest_info.get('oracle_success', False)
            }
        
        result = {
            'episode_id': self.current_episode_id,
            'instruction': self.current_instruction,
            'success': success,
            'total_steps': total_steps,
            'subtask_count': self.subtask_count,
            'detected_classes': list(self.detected_classes),
            'subtask_history': self.subtask_history,
            'metrics': metrics,
            'timestamp': datetime.now().isoformat()
        }
        
        # ä¿å­˜åˆ°vlmç›®å½•
        filepath = os.path.join(self.vlm_dir, 'result.json')
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        
        print(f"\n{'='*60}")
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜: {filepath}")
        print(f"   Steps: {total_steps} | Subtasks: {self.subtask_count}")
        if metrics:
            print(f"   Success: {metrics.get('success', success)} | SPL: {metrics.get('spl', 0.0):.4f}")
        print(f"{'='*60}")
        
        return filepath
    
    def record_action(self, action_name: str, action_id: int, vlm_response: Dict = None):
        """
        è®°å½•åŠ¨ä½œåˆ°å½“å‰å­ä»»åŠ¡æ–‡ä»¶ï¼ˆä¸llm_vlm_controlå…¼å®¹çš„æ ¼å¼ï¼‰
        
        Args:
            action_name: åŠ¨ä½œåç§°
            action_id: åŠ¨ä½œID
            vlm_response: VLMå“åº”å­—å…¸ï¼ˆå¯é€‰ï¼‰
        """
        if not self.current_subtask_file or not os.path.exists(self.current_subtask_file):
            return
        
        action_data = {
            "step": self.current_step,
            "action_name": action_name,
            "action_id": action_id,
        }
        
        if self.latest_info:
            action_data["distance_to_goal"] = self.latest_info.get("distance_to_goal", -1)
        
        if vlm_response:
            action_data["vlm_response"] = {
                k: vlm_response.get(k, "") 
                for k in ['observation', 'reasoning', 'action', 'progress_summary']
            }
        
        # è¯»å–å¹¶æ›´æ–°æ–‡ä»¶
        try:
            with open(self.current_subtask_file, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            if "actions" not in data:
                data["actions"] = []
            data["actions"].append(action_data)
            
            with open(self.current_subtask_file, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸ è®°å½•åŠ¨ä½œå¤±è´¥: {e}")
    
    def _print_subtask_info(self, response: Dict, is_initial: bool = False):
        """æ‰“å°å­ä»»åŠ¡ä¿¡æ¯"""
        title = "åˆå§‹å­ä»»åŠ¡" if is_initial else f"å­ä»»åŠ¡ #{self.subtask_count}"
        print(f"\nâœ… ===== {title} =====")
        print(f"ğŸŒ å…¨å±€æŒ‡ä»¤: {self.current_instruction}")
        print(f"ğŸ“ Waypoint: {response.get('waypoint', 'N/A')}")
        print(f"ğŸ‘ï¸  ç¯å¢ƒè§‚å¯Ÿ: {response.get('current_observation', 'N/A')}")
        print(f"ğŸ¯ ç›®çš„åœ°: {response.get('subtask_destination', 'N/A')}")
        print(f"ğŸ·ï¸  ç›®æ ‡Landmark: {response.get('subtask_destination_landmark', 'N/A')}")
        print(f"ğŸ“‹ å­ä»»åŠ¡æŒ‡ä»¤: {response.get('subtask_instruction', 'N/A')}")
        print(f"ğŸ’¡ è§„åˆ’æç¤º: {response.get('planning_hints', 'N/A')}")
        print(f"âœ“ å®Œæˆæ¡ä»¶: {response.get('completion_criteria', 'N/A')}")
        print(f"ğŸ æ˜¯å¦æœ€ç»ˆ: {response.get('is_final_subtask', False)}")
        print(f"âœ… {'='*50}\n")
    def add_waypoint(self, waypoint_description: str, position: np.ndarray = None) -> int:
        """
        æ·»åŠ è·¯å¾„ç‚¹åˆ°ç©ºé—´è®°å¿†
        
        Args:
            waypoint_description: è·¯å¾„ç‚¹æè¿°ï¼ˆæ ¼å¼: "<Area Type> - <Key Landmarks>"ï¼‰
            position: å½“å‰ä½ç½®åœ°å›¾åƒç´ åæ ‡ï¼ˆå¦‚æœä¸ºNoneåˆ™ä»mapperè·å–ï¼‰
            
        Returns:
            waypoint_id: æ–°æ·»åŠ çš„è·¯å¾„ç‚¹ID
        """
        self.waypoint_counter += 1
        waypoint_id = self.waypoint_counter
        
        # è·å–å½“å‰ä½ç½®ï¼ˆåœ°å›¾åƒç´ åæ ‡ï¼Œç”¨äºå¯è§†åŒ–ï¼‰
        if position is None:
            # ä»mapperè·å–å½“å‰åœ°å›¾åƒç´ åæ ‡ [x, y, theta]
            if hasattr(self.mapper, 'curr_loc'):
                position = self.mapper.curr_loc.copy()  # è¿™æ˜¯åœ°å›¾åƒç´ åæ ‡
            else:
                position = np.array([0, 0, 0])  # é»˜è®¤å€¼
        
        # åˆ›å»ºè·¯å¾„ç‚¹è®°å½•
        waypoint = {
            "id": waypoint_id,
            "waypoint": waypoint_description,
            "position": position.tolist() if isinstance(position, np.ndarray) else position,
            "step": self.current_step,
            "detected_objects": list(self.detected_classes) if hasattr(self, 'detected_classes') else [],
            "subtask_id": self.subtask_count
        }
        
        self.waypoint_memory.append(waypoint)
        
        print(f"  ğŸ“ Waypoint #{waypoint_id} å·²è®°å½•: {waypoint_description}")
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        self._save_waypoint_memory()
        
        return waypoint_id
    
    def get_waypoint_summary(self) -> str:
        """
        è·å–è·¯å¾„ç‚¹æ‘˜è¦ï¼ˆç”¨äºLLMæç¤ºè¯ï¼‰
        
        Returns:
            è·¯å¾„ç‚¹æ‘˜è¦å­—ç¬¦ä¸²
        """
        if not self.waypoint_memory:
            return "No waypoints recorded yet."
        
        summary_lines = ["Recorded Waypoints:"]
        for wp in self.waypoint_memory:
            # æ ¼å¼: "1. Living Room - near sofa and TV (Step 12)"
            summary_lines.append(
                f"{wp['id']}. {wp['waypoint']} (Step {wp['step']})"
            )
        
        return "\n".join(summary_lines)
    
    def _save_waypoint_memory(self):
        """ä¿å­˜è·¯å¾„ç‚¹è®°å¿†åˆ°JSONæ–‡ä»¶"""
        waypoint_file = os.path.join(self.vlm_dir, 'waypoint_memory.json')
        
        data = {
            "episode_id": self.current_episode_id,
            "instruction": self.current_instruction,
            "waypoints": self.waypoint_memory,
            "total_waypoints": len(self.waypoint_memory),
            "last_updated_step": self.current_step
        }
        
        try:
            with open(waypoint_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜waypointè®°å¿†å¤±è´¥: {e}")
    
    def visualize_waypoints_on_map(self, map_image: np.ndarray) -> np.ndarray:
        """
        åœ¨åœ°å›¾ä¸Šå¯è§†åŒ–è·¯å¾„ç‚¹
        
        Args:
            map_image: è¾“å…¥åœ°å›¾å›¾åƒï¼ˆBGRæ ¼å¼ï¼‰
            
        Returns:
            æ ‡æ³¨äº†è·¯å¾„ç‚¹çš„åœ°å›¾å›¾åƒ
        """
        if not self.waypoint_memory:
            return map_image
        
        # å¤åˆ¶åœ°å›¾é¿å…ä¿®æ”¹åŸå›¾
        annotated_map = map_image.copy()
        
        for wp in self.waypoint_memory:
            try:
                # è·å–ä½ç½®åæ ‡ï¼ˆåœ°å›¾åƒç´ åæ ‡ï¼‰
                pos = wp["position"]
                if isinstance(pos, list):
                    x, y = int(pos[0]), int(pos[1])
                else:
                    continue
                
                # ç»˜åˆ¶åœ†å½¢æ ‡è®°ï¼ˆæ·±çº¢è‰²ï¼‰
                cv2.circle(annotated_map, (x, y), 15, (0, 0, 139), -1)  # æ·±çº¢è‰²å¡«å……åœ† (BGR: 0,0,139)
                cv2.circle(annotated_map, (x, y), 15, (255, 255, 255), 2)  # ç™½è‰²è¾¹æ¡†
                
                # ç»˜åˆ¶IDæ•°å­—ï¼ˆç™½è‰²ï¼‰
                font = cv2.FONT_HERSHEY_SIMPLEX
                text = str(wp["id"])
                text_size = cv2.getTextSize(text, font, 0.6, 2)[0]
                text_x = x - text_size[0] // 2
                text_y = y + text_size[1] // 2
                cv2.putText(annotated_map, text, (text_x, text_y), 
                           font, 0.6, (255, 255, 255), 2, cv2.LINE_AA)
                
            except Exception as e:
                print(f"âš ï¸  æ ‡æ³¨waypoint {wp['id']} å¤±è´¥: {e}")
                continue
        
        return annotated_map
