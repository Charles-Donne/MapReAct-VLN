"""
åœ°å›¾å¯è§†åŒ–å·¥å…· - MapVisualizer
================================
èŒè´£ï¼š
1. åœ°å›¾æ¸²æŸ“ï¼ˆå…¨å±€åœ°å›¾ã€å±€éƒ¨åœ°å›¾ï¼‰
2. æ£€æµ‹ç»“æœå¯è§†åŒ–
3. è½¨è¿¹ç»˜åˆ¶
4. æ–‡ä»¶ä¿å­˜

è®¾è®¡åŸåˆ™ï¼š
- å•ä¸€èŒè´£ï¼šåªè´Ÿè´£å¯è§†åŒ–å’Œä¿å­˜ï¼Œä¸æ¶‰åŠå»ºå›¾é€»è¾‘
- è§£è€¦ï¼šç‹¬ç«‹äºControllerå’ŒMapper
- å¯å¤ç”¨ï¼šæ”¯æŒå¤šç§å¯è§†åŒ–åœºæ™¯
"""

import os
import cv2
import copy
import numpy as np
from PIL import Image
from typing import List, Tuple, Optional, Dict, Any

from vlnce_baselines.visualization import rendering as vu
from vlnce_baselines.config_system.constants import (
    color_palette, 
    detection_colors,
    detection_thickness,
    landmark_marker_color,
    landmark_marker_border,
    landmark_marker_radius,
)


class MapVisualizer:
    """åœ°å›¾å¯è§†åŒ–å™¨ - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰å¯è§†åŒ–å’Œä¿å­˜é€»è¾‘"""
    
    def __init__(self, 
                 results_dir: str,
                 resolution: int = 5,
                 map_shape: Tuple[int, int] = (480, 480)):
        """
        Args:
            results_dir: ä¿å­˜æ ¹ç›®å½•ï¼ˆå¦‚ï¼šdata/manual_navigationï¼‰
            resolution: åœ°å›¾åˆ†è¾¨ç‡ï¼ˆcm/pixelï¼‰
            map_shape: åœ°å›¾å°ºå¯¸
        """
        self.results_dir = results_dir
        self.resolution = resolution
        self.map_shape = map_shape
        self.color_palette = [int(x * 255.) for x in color_palette]
        
        # æ³¨æ„ï¼šä¸åœ¨åˆå§‹åŒ–æ—¶åˆ›å»ºç›®å½•ï¼Œè€Œæ˜¯åœ¨ä¿å­˜æ—¶æ ¹æ®episode_idåŠ¨æ€åˆ›å»º
    
    def _create_episode_directories(self, episode_id: int):
        """ä¸ºç‰¹å®šepisodeåˆ›å»ºä¿å­˜ç›®å½•"""
        episode_dir = os.path.join(self.results_dir, f'episode_{episode_id}')
        dirs = ['rgb', 'global_map', 'local_map', 'detection']
        for dir_name in dirs:
            os.makedirs(os.path.join(episode_dir, dir_name), exist_ok=True)
        return episode_dir
    
    # ========== æ¸²æŸ“æ–¹æ³• ==========
    
    def render_global_map(self,
                         full_map: np.ndarray,
                         trajectory_points: List[Tuple[int, int]],
                         detected_classes: List[str],
                         floor: Optional[np.ndarray] = None,
                         current_pose: Optional[Tuple[float, float, float]] = None,
                         landmark_classes: Optional[List[str]] = None,
                         landmark_config: Optional[Dict] = None) -> Tuple[np.ndarray, np.ndarray]:
        """
        æ¸²æŸ“å…¨å±€åœ°å›¾ï¼ˆä¸¥æ ¼æŒ‰ç…§ZS_Evaluatorçš„æ¸²æŸ“é€»è¾‘ + å¹³æ»‘è½¨è¿¹çº¿ï¼‰
        
        Args:
            full_map: [C, H, W] å…¨å±€åœ°å›¾
                [0] = obstacle map (éšœç¢ç‰©)
                [1] = explored map (å·²æ¢ç´¢)
                [2] = current position
                [3] = history position
                [4+] = semantic classes (ç”¨äºlandmarkæ ‡æ³¨ï¼Œä¸ç”¨äºflooræ¸²æŸ“)
            trajectory_points: [(x, y), ...] è½¨è¿¹åæ ‡åˆ—è¡¨ï¼ˆåƒç´ åæ ‡ï¼‰
            detected_classes: å·²æ£€æµ‹ç±»åˆ«åˆ—è¡¨
            floor: [H, W] flooråœ°å›¾ï¼ˆé€šè¿‡å½¢æ€å­¦æ–¹æ³•è®¡ç®—ï¼ŒåƒZS_Evaluatorï¼‰
            current_pose: (x, y, orientation) å½“å‰ä½å§¿
            landmark_classes: landmarkç±»åˆ«åˆ—è¡¨
            landmark_config: landmarké…ç½® {min_total_pixels, min_area_threshold}
        
        Returns:
            (sem_map_vis, global_map_rotated, landmarks)
            - sem_map_vis: åŸºç¡€æ¸²æŸ“åœ°å›¾ (480Ã—480)
            - global_map_rotated: æ—‹è½¬è°ƒæ•´åçš„åœ°å›¾ (480Ã—480)ï¼Œç®­å¤´æœä¸Š
            - landmarks: [(x, y, class_name), ...] æ ‡æ³¨åˆ—è¡¨
        
        æ¸²æŸ“å±‚æ¬¡ï¼ˆä¸¥æ ¼æŒ‰ç…§ZS_Evaluatorï¼‰:
            - ç™½è‰²(0): æœªæ¢ç´¢åŒºåŸŸ
            - æµ…ç°è‰²(2): å·²æ¢ç´¢è‡ªç”±ç©ºé—´ï¼ˆå…ˆæ¸²æŸ“ï¼‰
            - é»‘è‰²(1): éšœç¢ç‰©ï¼ˆè¦†ç›–å·²æ¢ç´¢ï¼‰
            - æµ…ç»¿è‰²(5): Floorï¼ˆé€šè¿‡å½¢æ€å­¦è®¡ç®—ï¼Œè¦†ç›–éšœç¢ç‰©ï¼‰
            - æ©™è‰²(3): Agentè½¨è¿¹ï¼ˆæœ€åè¦†ç›–ï¼‰
            
        æ³¨æ„ï¼šä¸æ¸²æŸ“bed/chairç­‰è¯­ä¹‰ç±»åˆ«çš„é¢œè‰²ï¼Œåªç”¨äºlandmarkæ ‡æ³¨
        """
        obstacle_map = full_map[0, ...]
        explored_map = full_map[1, ...]
        h, w = obstacle_map.shape
        
        # ===== é˜¶æ®µ1: åˆ›å»ºè¯­ä¹‰åœ°å›¾ï¼ˆä¸¥æ ¼æŒ‰ç…§ZS_Evaluatorçš„layeré¡ºåºï¼‰=====
        semantic_map = np.zeros((h, w), dtype=np.uint8)
        
        obstacle_mask = np.rint(obstacle_map) == 1
        explored_mask = np.rint(explored_map) == 1
        
        # ===== æ­£ç¡®çš„æ¸²æŸ“é¡ºåºï¼šé˜²æ­¢éšœç¢ç‰©è¢«è¦†ç›– =====
        # æ­£ç¡®é¡ºåºï¼šå·²æ¢ç´¢è‡ªç”±ç©ºé—´(åº•å±‚) â†’ Floor(ä¸­å±‚) â†’ éšœç¢ç‰©(é¡¶å±‚)
        # è¿™æ ·ç¡®ä¿éšœç¢ç‰©å§‹ç»ˆå¯è§ï¼Œä¸ä¼šè¢«Floorè¦†ç›–
        
        # Layer 1: å·²æ¢ç´¢è‡ªç”±ç©ºé—´ï¼ˆæµ…ç°è‰²ï¼‰- å…ˆç»˜åˆ¶åº•å±‚
        explored_free_mask = np.logical_and(explored_mask, ~obstacle_mask)
        semantic_map[explored_free_mask] = 2
        
        # Layer 2: Floorï¼ˆæµ…ç»¿è‰²ï¼‰- è¦†ç›–éƒ¨åˆ†è‡ªç”±ç©ºé—´
        if floor is not None:
            floor_mask = floor.astype(bool)
            floor_display_mask = np.logical_and(floor_mask, explored_mask)
            semantic_map[floor_display_mask] = 5  # æµ…ç»¿è‰²
        
        # Layer 3: éšœç¢ç‰©ï¼ˆé»‘è‰²ï¼‰- æœ€åç»˜åˆ¶ï¼Œç¡®ä¿è¦†ç›–Floorå’Œè‡ªç”±ç©ºé—´
        # è¿™æ ·éšœç¢ç‰©æ°¸è¿œå¯è§ï¼Œé˜²æ­¢ç¢°æ’
        semantic_map[obstacle_mask] = 1
        
        # ===== é˜¶æ®µ2: PILè°ƒè‰²æ¿æ¸²æŸ“ =====
        sem_map_vis = Image.new("P", (w, h))
        sem_map_vis.putpalette(self.color_palette)
        sem_map_vis.putdata(semantic_map.flatten().astype(np.uint8))
        sem_map_vis = sem_map_vis.convert("RGB")
        
        # åæ ‡ç³»å˜æ¢ï¼šç¿»è½¬Yè½´ + RGBâ†’BGR
        sem_map_vis = np.flipud(sem_map_vis)
        sem_map_vis = np.array(sem_map_vis)
        sem_map_vis = sem_map_vis[:, :, [2, 1, 0]]  # RGB â†’ BGR
        sem_map_vis = cv2.resize(sem_map_vis, (480, 480), interpolation=cv2.INTER_NEAREST)
        
        # ===== é˜¶æ®µ3: æå–Landmarkä½ç½®ï¼ˆä½†ä¸ç»˜åˆ¶ï¼‰=====
        landmarks = []
        if landmark_classes and landmark_config:
            landmarks = self._extract_landmarks(
                full_map, detected_classes, landmark_classes,
                landmark_config['min_total_pixels'],
                landmark_config['min_area_threshold']
            )
        
        # ===== é˜¶æ®µ4: æ—‹è½¬è°ƒæ•´ï¼ˆç®­å¤´æœä¸Šï¼Œå±…ä¸­240,240ï¼‰=====
        global_map_rotated = None
        if current_pose is not None:
            current_x, current_y, current_o = current_pose
            
            # è®¡ç®—agentåœ¨åœ°å›¾ä¸­çš„ä½ç½®
            map_x = current_x * 100.0 / self.resolution
            map_y = current_y * 100.0 / self.resolution
            agent_x = map_x * 480 / h
            agent_y = (w - map_y) * 480 / w
            
            # æ—‹è½¬ä½¿ç®­å¤´æœæ­£ä¸Šæ–¹
            rotation_angle = 90 - current_o
            rotation_center = (agent_x, agent_y)
            rotation_matrix = cv2.getRotationMatrix2D(rotation_center, rotation_angle, 1.0)
            
            # âœ… æ·»åŠ å¹³ç§»æ­¥éª¤ï¼šå°†æ—‹è½¬åçš„agentç§»åŠ¨åˆ°(240, 240)
            target_center = np.array([240, 240, 1])
            current_center = np.array([agent_x, agent_y, 1])
            translation = target_center[:2] - rotation_matrix @ current_center
            rotation_matrix[0, 2] += translation[0]
            rotation_matrix[1, 2] += translation[1]
            
            global_map_rotated = cv2.warpAffine(
                sem_map_vis, rotation_matrix, (480, 480),
                flags=cv2.INTER_NEAREST,
                borderMode=cv2.BORDER_CONSTANT,
                borderValue=(255, 255, 255)
            )
            
            # ===== é˜¶æ®µ5: åˆ›å»ºglobal_mapçš„æ˜¾ç¤ºå‰¯æœ¬ï¼ˆç”¨äºç»˜åˆ¶è½¨è¿¹å’Œlandmarkï¼‰=====
            global_map_with_trajectory = global_map_rotated.copy()
            
            # å…ˆåœ¨å‰¯æœ¬ä¸Šç»˜åˆ¶è½¨è¿¹çº¿ï¼ˆåº•å±‚ï¼‰
            if len(trajectory_points) >= 2:
                # è½¬æ¢è½¨è¿¹ç‚¹åˆ°æ—‹è½¬åçš„åæ ‡ç³»
                rotated_trajectory = []
                for x, y in trajectory_points:
                    # åŸå§‹åœ°å›¾åæ ‡ -> ç¿»è½¬Yè½´ -> ç¼©æ”¾åˆ°480x480
                    display_x = y * 480 / w
                    display_y = (h - 1 - x) * 480 / h
                    
                    # åº”ç”¨æ—‹è½¬å˜æ¢
                    point = np.array([display_x, display_y, 1])
                    rotated_point = rotation_matrix @ point
                    rotated_trajectory.append([int(round(rotated_point[0])), int(round(rotated_point[1]))])
                
                # ç»˜åˆ¶å®å¿ƒè½¨è¿¹çº¿ï¼ˆ2åƒç´ å®½ï¼‰
                if len(rotated_trajectory) >= 2:
                    trajectory_array = np.array(rotated_trajectory, dtype=np.int32)
                    cv2.polylines(global_map_with_trajectory, [trajectory_array], isClosed=False,
                                 color=(0, 165, 255), thickness=2, lineType=cv2.LINE_8)
            
            # å†åœ¨ä¸­å¿ƒç»˜åˆ¶ç®­å¤´ï¼ˆé¡¶å±‚ï¼Œè¦†ç›–è½¨è¿¹ï¼‰
            center_x, center_y = 240, 240
            arrow_angle = np.deg2rad(-90)  # æœä¸Š
            agent_pos = (center_x, center_y, arrow_angle)
            agent_arrow = vu.get_contour_points(agent_pos, origin=(0, 0), size=12)
            cv2.drawContours(global_map_with_trajectory, [agent_arrow], 0, (0, 0, 255), -1)
            
            # ===== é˜¶æ®µ6: åœ¨æ˜¾ç¤ºå‰¯æœ¬ä¸Šç»˜åˆ¶Landmarkæ ‡è®° =====
            if len(landmarks) > 0:
                landmark_summary = {}
                for marker_x, marker_y, cls_name in landmarks:
                    # è®¡ç®—åƒç´ æ•°
                    cls_idx = detected_classes.index(cls_name)
                    semantic_channel_idx = 4 + cls_idx
                    if semantic_channel_idx < full_map.shape[0]:
                        cls_mask = full_map[semantic_channel_idx, ...] > 0.5
                        pixel_count = int(cls_mask.sum())
                        if cls_name not in landmark_summary:
                            landmark_summary[cls_name] = {'count': 0, 'total_pixels': 0}
                        landmark_summary[cls_name]['count'] += 1
                        landmark_summary[cls_name]['total_pixels'] += pixel_count
                    
                    # è½¬æ¢landmarkåæ ‡åˆ°æ—‹è½¬åçš„åæ ‡ç³»
                    display_x = marker_x * 480 / w
                    display_y = (h - 1 - marker_y) * 480 / h
                    point = np.array([display_x, display_y, 1])
                    rotated_point = rotation_matrix @ point
                    
                    # ç»˜åˆ¶ç´«è‰²åœ†çƒï¼ˆåœ¨æ˜¾ç¤ºå‰¯æœ¬ä¸Šï¼‰
                    cv2.circle(global_map_with_trajectory, 
                              (int(rotated_point[0]), int(rotated_point[1])), 
                              landmark_marker_radius, landmark_marker_color, -1)
                    cv2.circle(global_map_with_trajectory, 
                              (int(rotated_point[0]), int(rotated_point[1])), 
                              landmark_marker_radius, landmark_marker_border, 1)
                
                # é™é»˜å¤„ç†ï¼Œä¸è¾“å‡ºæ ‡æ³¨ç»Ÿè®¡
        
        # è¿”å›ï¼šåŸºç¡€åœ°å›¾ + æ˜¾ç¤ºå‰¯æœ¬ï¼ˆå¸¦è½¨è¿¹å’Œlandmarkï¼‰ + æ— è½¨è¿¹çš„æ—‹è½¬åœ°å›¾ï¼ˆä¾›local_mapè£å‰ªï¼‰
        return sem_map_vis, global_map_with_trajectory, landmarks, global_map_rotated
    
    def render_local_map(self, 
                        global_map_clean: np.ndarray,
                        trajectory_points: List[Tuple[int, int]],
                        current_pose: Tuple[float, float, float],
                        hfov: float = 90.0) -> np.ndarray:
        """
        æ¸²æŸ“å±€éƒ¨åœ°å›¾ï¼ˆä»æ— è½¨è¿¹çš„å…¨å±€åœ°å›¾è£å‰ªï¼Œç‹¬ç«‹ç»˜åˆ¶localè½¨è¿¹ï¼‰
        
        Args:
            global_map_clean: æ—‹è½¬åçš„å…¨å±€åœ°å›¾ï¼ˆæ— è½¨è¿¹ï¼Œ480Ã—480ï¼‰ï¼Œagentå·²å±…ä¸­åœ¨(240,240)
            trajectory_points: [(x, y), ...] åŸå§‹è½¨è¿¹åæ ‡åˆ—è¡¨ï¼ˆåœ°å›¾åƒç´ åæ ‡ï¼‰
            current_pose: (x, y, orientation) å½“å‰ä½å§¿ï¼ˆç±³ï¼‰
            hfov: æ°´å¹³è§†é‡è§’åº¦ï¼ˆé»˜è®¤90åº¦ï¼‰
        
        Returns:
            local_map: å±€éƒ¨åœ°å›¾ (400Ã—400)ï¼Œè£å‰ªè‡ª480Ã—480
        """
        if global_map_clean is None:
            return None
        
        # ===== é˜¶æ®µ1: ä»æ— è½¨è¿¹çš„åœ°å›¾è£å‰ªä¸­å¿ƒ240Ã—240åŒºåŸŸï¼ˆå¯¹åº”12mÃ—12mï¼‰=====
        center_x, center_y = 240, 240
        crop_size = 240
        crop_half = crop_size // 2
        
        x1 = center_x - crop_half
        x2 = center_x + crop_half
        y1 = center_y - crop_half
        y2 = center_y + crop_half
        
        local_map = global_map_clean[y1:y2, x1:x2].copy()
        
        # ===== é˜¶æ®µ2: æ‰©å……åˆ°480Ã—480 =====
        local_map = cv2.resize(local_map, (480, 480), interpolation=cv2.INTER_NEAREST)
        
        # ===== é˜¶æ®µ3: åœ¨local_mapä¸Šç‹¬ç«‹ç»˜åˆ¶è½¨è¿¹çº¿ =====
        if len(trajectory_points) >= 2:
            # è®¡ç®—è£å‰ªåŒºåŸŸåœ¨global_mapä¸­çš„è¾¹ç•Œ
            h, w = global_map_clean.shape[:2]
            
            # è½¬æ¢è½¨è¿¹ç‚¹åˆ°æ—‹è½¬åçš„globalåæ ‡ç³»ï¼Œç„¶åæ˜ å°„åˆ°localåæ ‡
            local_trajectory = []
            for x, y in trajectory_points:
                # åŸå§‹åœ°å›¾åæ ‡ -> ç¿»è½¬Yè½´ -> ç¼©æ”¾åˆ°480x480
                display_x = y * 480 / w
                display_y = (h - 1 - x) * 480 / h
                
                # åº”ç”¨æ—‹è½¬å˜æ¢ï¼ˆä½¿ç”¨global_mapçš„æ—‹è½¬çŸ©é˜µï¼‰
                current_x, current_y, current_o = current_pose
                map_x = current_x * 100.0 / self.resolution
                map_y = current_y * 100.0 / self.resolution
                agent_x = map_x * 480 / h
                agent_y = (w - map_y) * 480 / w
                rotation_angle = 90 - current_o
                rotation_center = (agent_x, agent_y)
                rotation_matrix = cv2.getRotationMatrix2D(rotation_center, rotation_angle, 1.0)
                
                # æ·»åŠ å¹³ç§»åˆ°ä¸­å¿ƒ
                target_center = np.array([240, 240, 1])
                current_center = np.array([agent_x, agent_y, 1])
                translation = target_center[:2] - rotation_matrix @ current_center
                rotation_matrix[0, 2] += translation[0]
                rotation_matrix[1, 2] += translation[1]
                
                point = np.array([display_x, display_y, 1])
                rotated_point = rotation_matrix @ point
                
                # è½¬æ¢åˆ°local_mapåæ ‡ç³»ï¼ˆè£å‰ªåŒºåŸŸ120-360æ˜ å°„åˆ°0-480ï¼‰
                local_x = (rotated_point[0] - 120) * 2  # 240åŒºåŸŸæ”¾å¤§2å€åˆ°480
                local_y = (rotated_point[1] - 120) * 2
                
                # åªæ·»åŠ åœ¨å¯è§èŒƒå›´å†…çš„ç‚¹
                if 0 <= local_x < 480 and 0 <= local_y < 480:
                    local_trajectory.append([int(round(local_x)), int(round(local_y))])
            
            # ç»˜åˆ¶å¹³æ»‘è½¨è¿¹çº¿ï¼ˆ3åƒç´ å®½ï¼‰
            if len(local_trajectory) >= 2:
                trajectory_array = np.array(local_trajectory, dtype=np.int32)
                cv2.polylines(local_map, [trajectory_array], isClosed=False,
                             color=(0, 165, 255), thickness=3, lineType=cv2.LINE_8)
        
        # ===== é˜¶æ®µ4: ç»˜åˆ¶FOVæ‰‡å½¢ï¼ˆ5ç±³è§†é‡åŠå¾„ï¼‰=====
        # 480åƒç´  = 12mï¼Œæ‰€ä»¥1åƒç´  = 2.5cm
        # 5ç±³ = 500cm Ã· 2.5cm/pixel = 200åƒç´ 
        fov_center_x, fov_center_y = 240, 240
        fov_radius = 200  # 5ç±³è§†é‡åŠå¾„
        
        # Agentæœä¸Šï¼ˆ-90åº¦ï¼‰ï¼ŒFOVæ‰‡å½¢ä¸­å¿ƒçº¿ä¹Ÿæœä¸Š
        fov_center_angle = -90
        fov_start_angle = fov_center_angle - hfov / 2
        fov_end_angle = fov_center_angle + hfov / 2
        
        # ç»˜åˆ¶FOVæ‰‡å½¢è½®å»“ï¼ˆæ·±è“è‰²ï¼Œç²—çº¿ï¼‰
        fov_outline_color = (255, 128, 0)  # æ·±è“è‰²BGR
        fov_outline_thickness = 3
        cv2.ellipse(local_map, (fov_center_x, fov_center_y), (fov_radius, fov_radius),
                   0, fov_start_angle, fov_end_angle, fov_outline_color, fov_outline_thickness)
        
        # ç»˜åˆ¶æ‰‡å½¢ä¸¤æ¡è¾¹çº¿
        import math
        # å·¦è¾¹çº¿
        left_angle_rad = math.radians(fov_start_angle)
        left_end_x = int(fov_center_x + fov_radius * math.cos(left_angle_rad))
        left_end_y = int(fov_center_y + fov_radius * math.sin(left_angle_rad))
        cv2.line(local_map, (fov_center_x, fov_center_y), (left_end_x, left_end_y),
                fov_outline_color, fov_outline_thickness)
        
        # å³è¾¹çº¿
        right_angle_rad = math.radians(fov_end_angle)
        right_end_x = int(fov_center_x + fov_radius * math.cos(right_angle_rad))
        right_end_y = int(fov_center_y + fov_radius * math.sin(right_angle_rad))
        cv2.line(local_map, (fov_center_x, fov_center_y), (right_end_x, right_end_y),
                fov_outline_color, fov_outline_thickness)
        
        # ===== é˜¶æ®µ5: ç»˜åˆ¶æœä¸Šçš„å¤§ç®­å¤´ï¼ˆsize=24ï¼‰=====
        arrow_color = (0, 0, 255)  # äº®çº¢è‰²BGR
        arrow_angle = np.deg2rad(-90)  # æœä¸Š
        agent_pos = (fov_center_x, fov_center_y, arrow_angle)
        agent_arrow = vu.get_contour_points(agent_pos, origin=(0, 0), size=24)
        cv2.drawContours(local_map, [agent_arrow], 0, arrow_color, -1)
        
        # ===== é˜¶æ®µ6: è£å‰ªä¸­å¿ƒ400Ã—400 =====
        local_map_cropped = local_map[40:440, 40:440].copy()
        
        return local_map_cropped
    
    def render_detection_bbox(self, 
                              rgb: np.ndarray,
                              detections,  # sv.Detections object
                              labels: List[str],
                              landmark_classes: Optional[List[str]] = None,
                              mapping_classes: Optional[List[str]] = None) -> np.ndarray:
        """
        ç›´æ¥åœ¨RGBä¸Šæ¸²æŸ“è¾¹ç•Œæ¡†ï¼ˆåªæ ‡æ³¨Landmarkç±»åˆ«ï¼‰
        
        Args:
            rgb: RGBå›¾åƒ (H, W, 3) BGRæ ¼å¼
            detections: supervision Detectionså¯¹è±¡
            labels: æ ‡ç­¾åˆ—è¡¨ (ä¾‹å¦‚: ["chair 0.85", "table 0.92"])
            landmark_classes: Landmarkç±»åˆ«åˆ—è¡¨ï¼ˆåªæ ‡æ³¨è¿™äº›ç±»åˆ«ï¼‰
            mapping_classes: Mappingç±»åˆ«åˆ—è¡¨ï¼ˆä¸æ ‡æ³¨ï¼Œä»…ç”¨äºå»ºå›¾ï¼‰
        
        Returns:
            detection_vis: æ£€æµ‹å¯è§†åŒ–å›¾åƒï¼ˆåªæ˜¾ç¤ºLandmarkè¾¹ç•Œæ¡†ï¼‰
        """
        detection_vis = rgb.copy()
        
        if detections is None or len(detections.xyxy) == 0:
            return detection_vis
        
        # ç»Ÿè®¡æ£€æµ‹åˆ°çš„landmark
        detected_landmarks = []
        
        for i in range(len(detections.xyxy)):
            bbox = detections.xyxy[i]
            label = labels[i] if i < len(labels) else f"object_{i}"
            
            # æå–ç±»åˆ«åå’Œç½®ä¿¡åº¦
            parts = label.split()
            label_name = parts[0] if len(parts) > 0 else "unknown"
            confidence = float(parts[-1]) if len(parts) > 1 else 0.0
            
            # åªæ ‡æ³¨åœ¨landmark_classesä¸­çš„ç±»åˆ«
            is_landmark = landmark_classes and label_name in landmark_classes
            if not is_landmark:
                continue  # è·³è¿‡éLandmarkç±»åˆ«
            
            detected_landmarks.append((label_name, confidence))
            
            # ä½¿ç”¨é†’ç›®çš„é»„è‰²ç²—æ¡†æ ‡æ³¨Landmark
            color = detection_colors["landmark"]
            thickness = detection_thickness["landmark"]
            
            # ç”»è¾¹ç•Œæ¡†
            x1, y1, x2, y2 = map(int, bbox)
            cv2.rectangle(detection_vis, (x1, y1), (x2, y2), color, thickness)
            
            # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬ï¼ˆLandmarkä¸“å±ï¼‰
            text = f"{label_name} {confidence:.2f}"
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.6
            font_thickness = 2
            
            # è®¡ç®—æ–‡æœ¬å°ºå¯¸
            (text_w, text_h), baseline = cv2.getTextSize(text, font, font_scale, font_thickness)
            
            # ç”»æ ‡ç­¾èƒŒæ™¯ï¼ˆé»„è‰²ï¼‰
            cv2.rectangle(detection_vis, 
                         (x1, y1 - text_h - baseline - 5), 
                         (x1 + text_w + 5, y1), 
                         color, -1)
            
            # ç”»æ ‡ç­¾æ–‡å­—ï¼ˆé»‘è‰²ï¼Œæ¸…æ™°æ˜“è¯»ï¼‰
            cv2.putText(detection_vis, text, 
                       (x1 + 2, y1 - baseline - 2),
                       font, font_scale, (0, 0, 0), font_thickness)
        
        # é™é»˜å¤„ç†ï¼Œä¸è¾“å‡ºæ£€æµ‹ç»Ÿè®¡
        
        return detection_vis
    
    # ========== ä¿å­˜æ–¹æ³• ==========
    
    def save_rgb(self, step: int, episode_id: int, rgb: np.ndarray) -> str:
        """
        ä¿å­˜åŸå§‹RGBå¸§
        
        Args:
            step: æ­¥æ•°
            episode_id: episode ID
            rgb: RGBå›¾åƒ (H, W, 3) BGRæ ¼å¼
        
        Returns:
            save_path: ä¿å­˜è·¯å¾„
        """
        episode_dir = self._create_episode_directories(episode_id)
        save_path = os.path.join(episode_dir, 'rgb', f'step-{step}.png')
        cv2.imwrite(save_path, rgb)
        return save_path
    
    def save_global_map(self, 
                       step: int,
                       episode_id: int,
                       global_map: np.ndarray) -> str:
        """
        ä¿å­˜å…¨å±€åœ°å›¾ï¼ˆè£å‰ªä¸º400Ã—400ï¼‰
        
        Args:
            step: æ­¥æ•°
            episode_id: episode ID
            global_map: æ—‹è½¬åçš„å…¨å±€åœ°å›¾ (480Ã—480)
        
        Returns:
            save_path: ä¿å­˜è·¯å¾„
        """
        if global_map is None:
            return None
        
        # è£å‰ªä¸­å¿ƒ400Ã—400
        global_map_cropped = global_map[40:440, 40:440]
        
        # ç®€åŒ–è·¯å¾„ï¼šdata/manual_navigation/episode_X/global_map/step-Y.png
        episode_dir = self._create_episode_directories(episode_id)
        save_path = os.path.join(episode_dir, 'global_map', f'step-{step}.png')
        cv2.imwrite(save_path, global_map_cropped, [cv2.IMWRITE_PNG_COMPRESSION, 1])
        return save_path
    
    def save_local_map(self,
                      step: int,
                      episode_id: int,
                      local_map: np.ndarray) -> str:
        """
        ä¿å­˜å±€éƒ¨åœ°å›¾
        
        Args:
            step: æ­¥æ•°
            episode_id: episode ID
            local_map: å±€éƒ¨åœ°å›¾ (400Ã—400)
        
        Returns:
            save_path: ä¿å­˜è·¯å¾„
        """
        if local_map is None:
            return None
        
        # ç®€åŒ–è·¯å¾„ï¼šdata/manual_navigation/episode_X/local_map/step-Y.png
        episode_dir = self._create_episode_directories(episode_id)
        save_path = os.path.join(episode_dir, 'local_map', f'step-{step}.png')
        cv2.imwrite(save_path, local_map, [cv2.IMWRITE_PNG_COMPRESSION, 1])
        return save_path
    
    def save_detection(self,
                      step: int,
                      episode_id: int,
                      detection_vis: np.ndarray) -> str:
        """
        ä¿å­˜æ£€æµ‹å¯è§†åŒ–
        
        Args:
            step: æ­¥æ•°
            episode_id: episode ID
            detection_vis: æ£€æµ‹å¯è§†åŒ–å›¾åƒ
        
        Returns:
            save_path: ä¿å­˜è·¯å¾„
        """
        if detection_vis is None:
            return None
        
        # ç®€åŒ–è·¯å¾„ï¼šdata/manual_navigation/episode_X/detection/step-Y.png
        episode_dir = self._create_episode_directories(episode_id)
        save_path = os.path.join(episode_dir, 'detection', f'step-{step}.png')
        cv2.imwrite(save_path, detection_vis)
        return save_path
    
    # ========== ä¸€é”®ä¿å­˜æ–¹æ³• ==========
    
    def save_step_visualization(self, 
                               step: int,
                               episode_id: int,
                               rgb: np.ndarray,
                               full_map: np.ndarray,
                               trajectory_points: List[Tuple[int, int]],
                               detected_classes: List[str],
                               current_pose: Tuple[float, float, float],
                               floor: Optional[np.ndarray] = None,
                               hfov: float = 90.0,
                               detections=None,  # sv.Detectionså¯¹è±¡ï¼ˆæ–°ï¼‰
                               labels: Optional[List[str]] = None,
                               landmark_classes: Optional[List[str]] = None,
                               mapping_classes: Optional[List[str]] = None,  # æ–°å¢
                               landmark_config: Optional[Dict] = None,
                               masks: Optional[np.ndarray] = None) -> Dict[str, str]:  # å…¼å®¹æ—§å‚æ•°
        """
        ä¸€é”®ä¿å­˜å½“å‰æ­¥éª¤çš„æ‰€æœ‰å¯è§†åŒ–ï¼ˆæ”¯æŒæ–°detectionæ¸²æŸ“ + å¹³æ»‘è½¨è¿¹çº¿ï¼‰
        
        Args:
            trajectory_points: [(x, y), ...] è½¨è¿¹åæ ‡åˆ—è¡¨ï¼ˆåƒç´ åæ ‡ï¼‰
            floor: [H, W] flooråœ°å›¾ï¼ˆé€šè¿‡å½¢æ€å­¦æ–¹æ³•è®¡ç®—ï¼ŒåƒZS_Evaluatorï¼‰
            detections: supervision Detectionså¯¹è±¡ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
            masks: æ£€æµ‹æ©ç ï¼ˆå‘åå…¼å®¹ï¼Œå·²åºŸå¼ƒï¼‰
            mapping_classes: Mappingç±»åˆ«åˆ—è¡¨
            landmark_classes: Landmarkç±»åˆ«åˆ—è¡¨
        
        Returns:
            paths: ä¿å­˜è·¯å¾„å­—å…¸ {'rgb', 'global_map', 'local_map', 'detection'}
            landmarks: Landmarkåˆ—è¡¨
            
        æ³¨æ„ï¼šflooré€šè¿‡å½¢æ€å­¦æ–¹æ³•è®¡ç®—ï¼ˆåƒZS_Evaluator._process_mapï¼‰
        """
        paths = {}
        
        # 1. ä¿å­˜RGB
        paths['rgb'] = self.save_rgb(step, episode_id, rgb)
        
        # 2. æ¸²æŸ“å¹¶ä¿å­˜å…¨å±€åœ°å›¾ï¼ˆflooré€šè¿‡å½¢æ€å­¦æ–¹æ³•è®¡ç®— + å¹³æ»‘è½¨è¿¹çº¿ï¼‰
        _, global_map_with_trajectory, landmarks, global_map_clean = self.render_global_map(
            full_map, trajectory_points, detected_classes, floor,
            current_pose, landmark_classes, landmark_config
        )
        paths['global_map'] = self.save_global_map(step, episode_id, global_map_with_trajectory)
        
        # 3. æ¸²æŸ“å¹¶ä¿å­˜å±€éƒ¨åœ°å›¾ï¼ˆä»æ— è½¨è¿¹åœ°å›¾è£å‰ªï¼Œç‹¬ç«‹ç»˜åˆ¶è½¨è¿¹ï¼‰
        local_map = self.render_local_map(global_map_clean, trajectory_points, current_pose, hfov)
        paths['local_map'] = self.save_local_map(step, episode_id, local_map)        # 4. æ¸²æŸ“å¹¶ä¿å­˜æ£€æµ‹ç»“æœ
        if detections is not None and labels is not None:
            detection_vis = self.render_detection_bbox(
                rgb, detections, labels, 
                landmark_classes, mapping_classes
            )
            paths['detection'] = self.save_detection(step, episode_id, detection_vis)
        
        return paths, landmarks
    
    # ========== è¾…åŠ©æ–¹æ³• ==========
    
    def _extract_landmarks(self,
                          full_map: np.ndarray,
                          detected_classes: List[str],
                          landmark_classes: List[str],
                          min_total_pixels: int,
                          min_area_threshold: int) -> List[Tuple[int, int, str]]:
        """æå–landmarkæ ‡è®°ä½ç½®
        
        æµç¨‹ï¼š
        1. éå†landmark_classesï¼ˆå¦‚cabinetï¼‰
        2. æ£€æŸ¥æ˜¯å¦åœ¨detected_classesä¸­
        3. è®¡ç®—è¯­ä¹‰é€šé“ç´¢å¼•ï¼šsemantic_channel_idx = 4 + detected_classes.index(cls_name)
        4. ä»full_map[semantic_channel_idx]æå–mask
        5. å½¢æ€å­¦é—­è¿ç®—ï¼šå¡«è¡¥é—´éš™ï¼Œåˆå¹¶ç›¸è¿‘åŒºåŸŸ
        6. è¿é€šåŸŸåˆ†æï¼Œè¿‡æ»¤é¢ç§¯ < min_area_threshold
        7. ç©ºé—´åˆå¹¶ï¼ˆè·ç¦» < landmark_merge_distanceï¼‰
        
        Returns:
            List of (cx, cy, class_name)
        """
        if not landmark_classes or len(detected_classes) == 0:
            return []
        
        spatial_regions = {}
        landmark_found = False
        
        for cls_name in landmark_classes:
            if cls_name not in detected_classes:
                continue
            
            cls_idx = detected_classes.index(cls_name)
            semantic_channel_idx = 4 + cls_idx
            
            if semantic_channel_idx >= full_map.shape[0]:
                continue
            
            cls_mask = full_map[semantic_channel_idx, ...] > 0.5
            num_pixels = cls_mask.sum()
            
            if num_pixels < min_total_pixels:
                continue
            
            # å½¢æ€å­¦é—­è¿ç®—ï¼šå¡«è¡¥é—´éš™ï¼Œåˆå¹¶ç›¸è¿‘åŒºåŸŸ
            # ä½¿ç”¨7Ã—7æ ¸ï¼Œå¯ä»¥å¡«è¡¥è·ç¦»3-4åƒç´ çš„é—´éš™ï¼Œåˆå¹¶è¢«Winner-Takes-Allåˆ†å‰²çš„åŒºåŸŸ
            cls_mask_uint8 = cls_mask.astype(np.uint8)
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
            cls_mask_closed = cv2.morphologyEx(cls_mask_uint8, cv2.MORPH_CLOSE, kernel)
            
            # è¿é€šæ€§åˆ†æï¼ˆåœ¨é—­è¿ç®—åçš„maskä¸Šï¼‰
            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(
                cls_mask_closed, connectivity=8)
            
            for i in range(1, num_labels):
                area = stats[i, cv2.CC_STAT_AREA]
                cx, cy = int(centroids[i][0]), int(centroids[i][1])
                
                if area < min_area_threshold:
                    continue
                
                # æ£€æŸ¥ç©ºé—´åˆå¹¶ï¼ˆä½¿ç”¨constant.pyé…ç½®çš„è·ç¦»ï¼‰
                from vlnce_baselines.config_system.constants import landmark_merge_distance
                merged = False
                for existing_pos in list(spatial_regions.keys()):
                    ex_cx, ex_cy = existing_pos
                    dist = np.sqrt((cx - ex_cx)**2 + (cy - ex_cy)**2)
                    if dist < landmark_merge_distance:
                        spatial_regions[existing_pos].append((area, cls_name))
                        merged = True
                        break
                
                if not merged:
                    spatial_regions[(cx, cy)] = [(area, cls_name)]
                    if not landmark_found:
                        landmark_found = True
        landmarks = []
        for (cx, cy), candidates in spatial_regions.items():
            candidates.sort(key=lambda x: x[0], reverse=True)
            dominant_class = candidates[0][1]
            area = candidates[0][0]
            landmarks.append((cx, cy, dominant_class))
            print(f"  ğŸ“ {dominant_class} @({cx},{cy}) - {area}px")
        
        return landmarks


# ========== ä¾¿æ·å‡½æ•° ==========

def create_visualizer(results_dir: str, 
                     resolution: int = 5,
                     map_shape: Tuple[int, int] = (480, 480)) -> MapVisualizer:
    """åˆ›å»ºMapVisualizerå®ä¾‹"""
    return MapVisualizer(results_dir, resolution, map_shape)
