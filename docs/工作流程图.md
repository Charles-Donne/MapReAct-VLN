# VLM Navigation System - å·¥ä½œæµç¨‹å›¾

## ç³»ç»Ÿæ¶æ„æ€»è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          VLM Navigation System                            â”‚
â”‚                    (Hierarchical Planning & Execution)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Episode Initialization      â”‚
                    â”‚   - Reset environment         â”‚
                    â”‚   - Load instruction          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   360Â° Panorama Scan          â”‚
                    â”‚   (12 steps Ã— 30Â° = 360Â°)     â”‚
                    â”‚                               â”‚
                    â”‚   Collect 4-Direction Views:  â”‚
                    â”‚   â€¢ Step 0:  Front (0Â°)       â”‚
                    â”‚   â€¢ Step 3:  Left (90Â°)       â”‚
                    â”‚   â€¢ Step 6:  Back (180Â°)      â”‚
                    â”‚   â€¢ Step 9:  Right (270Â°)     â”‚
                    â”‚                               â”‚
                    â”‚   Build Initial Semantic Map  â”‚
                    â”‚   Detect Objects (GroundedSAM)â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   HIGH-LEVEL PLANNING (LLM)   â”‚
                    â”‚   Model: GPT-4o / Claude      â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚ Input:                        â”‚
                    â”‚   â€¢ Global instruction        â”‚
                    â”‚   â€¢ 4-direction RGB images    â”‚
                    â”‚   â€¢ Global semantic map       â”‚
                    â”‚   â€¢ Local semantic map        â”‚
                    â”‚   â€¢ Detected landmarks list   â”‚
                    â”‚                               â”‚
                    â”‚ Process:                      â”‚
                    â”‚   â€¢ Analyze environment       â”‚
                    â”‚   â€¢ Decompose global task     â”‚
                    â”‚   â€¢ Define completion criteriaâ”‚
                    â”‚                               â”‚
                    â”‚ Output: Sub-task              â”‚
                    â”‚   {                           â”‚
                    â”‚     "subtask_destination":    â”‚
                    â”‚       "doorway",              â”‚
                    â”‚     "subtask_landmark":       â”‚
                    â”‚       "door",                 â”‚
                    â”‚     "subtask_instruction":    â”‚
                    â”‚       "Move to doorway",      â”‚
                    â”‚     "completion_criteria": {  â”‚
                    â”‚       "landmark_detection":   â”‚
                    â”‚         "door detected",      â”‚
                    â”‚       "destination_reached":  â”‚
                    â”‚         "<0.5m to doorway",   â”‚
                    â”‚       "spatial_relationship": â”‚
                    â”‚         "at door threshold"   â”‚
                    â”‚     }                         â”‚
                    â”‚   }                           â”‚
                    â”‚                               â”‚
                    â”‚ System Update:                â”‚
                    â”‚   landmark_classes = ["door"] â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  LOW-LEVEL EXECUTION (VLM)    â”‚
                    â”‚  Model: GPT-4o / Claude       â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚ Input (3 Images):             â”‚
                    â”‚   1. RGB: First-person view   â”‚
                    â”‚   2. Detection: Bounding boxesâ”‚
                    â”‚   3. Local Map: Top-down view â”‚
                    â”‚      - Green: Safe floor      â”‚
                    â”‚      - Black: Obstacles       â”‚
                    â”‚      - Orange: Trajectory     â”‚
                    â”‚      - Blue: Field of view    â”‚
                    â”‚                               â”‚
                    â”‚ Process:                      â”‚
                    â”‚   â€¢ Analyze safety            â”‚
                    â”‚   â€¢ Locate destination        â”‚
                    â”‚   â€¢ Plan collision-free path  â”‚
                    â”‚                               â”‚
                    â”‚ Output: Action                â”‚
                    â”‚   {                           â”‚
                    â”‚     "reasoning": "...",       â”‚
                    â”‚     "action": "MOVE_FORWARD", â”‚
                    â”‚     "progress_summary": "..." â”‚
                    â”‚   }                           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Execute Action              â”‚
                    â”‚   - MOVE_FORWARD (0.25m)      â”‚
                    â”‚   - TURN_LEFT (30Â°)           â”‚
                    â”‚   - TURN_RIGHT (30Â°)          â”‚
                    â”‚   - STOP (sub-task complete)  â”‚
                    â”‚                               â”‚
                    â”‚   Update State:               â”‚
                    â”‚   â€¢ Agent position            â”‚
                    â”‚   â€¢ Semantic map              â”‚
                    â”‚   â€¢ Trajectory (orange line)  â”‚
                    â”‚   â€¢ Detected objects          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚   STOP?       â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                            No â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€ Yes
                            â”‚              â”‚
                Loop back to VLM    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                                    â”‚ Verificationâ”‚
                                    â”‚ & Replanningâ”‚
                                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                                    â”‚ 360Â° Scan   â”‚
                                    â”‚ Update Map  â”‚
                                    â”‚             â”‚
                                    â”‚ Check:      â”‚
                                    â”‚ â˜‘ Landmark? â”‚
                                    â”‚ â˜‘ Distance? â”‚
                                    â”‚ â˜‘ Spatial?  â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                                    â”‚ Completed?  â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                    Yes â”€â”€â”€â”´â”€â”€â”€ No
                                    â”‚             â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”     â”‚
                            â”‚ Clear        â”‚     â”‚
                            â”‚ Trajectory   â”‚     â”‚
                            â”‚              â”‚     â”‚
                            â”‚ Generate     â”‚     â”‚
                            â”‚ Next Subtask â”‚     â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â”‚
                                    â”‚            â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    Loop back to
                                    LLM Planning
                                           â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                                    â”‚ Final       â”‚
                                    â”‚ Destination?â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                    Yes â”€â”€â”€â”´â”€â”€â”€ No
                                    â”‚             â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”     â”‚
                            â”‚ NAVIGATION   â”‚     â”‚
                            â”‚ COMPLETE     â”‚     â”‚
                            â”‚              â”‚     â”‚
                            â”‚ Save:        â”‚     â”‚
                            â”‚ â€¢ Trajectory â”‚     â”‚
                            â”‚ â€¢ GIF        â”‚     â”‚
                            â”‚ â€¢ Results    â”‚     â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
                                                 â”‚
                                        Loop to next subtask
```

---

## æ•°æ®æµè¯¦è§£

### 1ï¸âƒ£ LLM Planning Input â†’ Output

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         LLM PLANNING INPUT          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚
â”‚ Text:                               â”‚
â”‚   instruction = "Walk forward and   â”‚
â”‚                  exit the bedroom   â”‚
â”‚                  through the door." â”‚
â”‚                                     â”‚
â”‚ Images (4 directions):              â”‚
â”‚   [Front_0Â°.jpg]                    â”‚
â”‚   [Left_90Â°.jpg]                    â”‚
â”‚   [Back_180Â°.jpg]                   â”‚
â”‚   [Right_270Â°.jpg]                  â”‚
â”‚                                     â”‚
â”‚ Maps:                               â”‚
â”‚   [global_map.png] - Full explored  â”‚
â”‚   [local_map.png]  - Nearby region  â”‚
â”‚                                     â”‚
â”‚ Context:                            â”‚
â”‚   detected_landmarks = [            â”‚
â”‚     "floor", "wall", "bed",         â”‚
â”‚     "door", "window"                â”‚
â”‚   ]                                 â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
         â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
         â•‘  LLM (GPT-4o)  â•‘
         â•‘  ~2000 tokens  â•‘
         â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        LLM PLANNING OUTPUT          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚
â”‚ {                                   â”‚
â”‚   "subtask_destination": "doorway", â”‚
â”‚   "subtask_landmark": "door",       â”‚
â”‚   "subtask_instruction":            â”‚
â”‚     "Walk straight to the doorway", â”‚
â”‚   "completion_criteria": {          â”‚
â”‚     "landmark_detection":           â”‚
â”‚       "door detected and visible",  â”‚
â”‚     "destination_reached":          â”‚
â”‚       "within 0.5m of doorway",     â”‚
â”‚     "spatial_relationship":         â”‚
â”‚       "standing at door threshold"  â”‚
â”‚   },                                â”‚
â”‚   "current_room_type": "bedroom"    â”‚
â”‚ }                                   â”‚
â”‚                                     â”‚
â”‚ â†’ System updates:                   â”‚
â”‚   landmark_classes = ["door"]       â”‚
â”‚   (Replaces previous landmark)      â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2ï¸âƒ£ VLM Action Input â†’ Output

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        VLM ACTION INPUT             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚
â”‚ Context:                            â”‚
â”‚   subtask_destination = "doorway"   â”‚
â”‚   subtask_instruction = "Walk..."   â”‚
â”‚   progress_summary = "Moved 2x"     â”‚
â”‚   detected_landmarks = "door"       â”‚
â”‚                                     â”‚
â”‚ Images (3 types):                   â”‚
â”‚                                     â”‚
â”‚ 1. [RGB_view.jpg]                   â”‚
â”‚    â””â”€ First-person perspective      â”‚
â”‚       What agent sees now           â”‚
â”‚                                     â”‚
â”‚ 2. [Detection_view.jpg]             â”‚
â”‚    â””â”€ Bounding boxes overlay        â”‚
â”‚       Detected objects with labels  â”‚
â”‚                                     â”‚
â”‚ 3. [Local_map.png]                  â”‚
â”‚    â””â”€ Top-down semantic map         â”‚
â”‚       â€¢ White: Unexplored           â”‚
â”‚       â€¢ Black: Obstacles (AVOID!)   â”‚
â”‚       â€¢ Green: Safe floor (OK)      â”‚
â”‚       â€¢ Orange: Trajectory          â”‚
â”‚       â€¢ Red arrow: Agent position   â”‚
â”‚       â€¢ Blue semicircle: FOV        â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
         â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
         â•‘  VLM (GPT-4o)  â•‘
         â•‘  ~1200 tokens  â•‘
         â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        VLM ACTION OUTPUT            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚
â”‚ {                                   â”‚
â”‚   "reasoning":                      â”‚
â”‚     "RGB: Doorway 3m ahead.         â”‚
â”‚      Detection: door detected.      â”‚
â”‚      Local map: clear green path,   â”‚
â”‚      no black obstacles ahead.      â”‚
â”‚      Safe to move forward.",        â”‚
â”‚                                     â”‚
â”‚   "action": "MOVE_FORWARD",         â”‚
â”‚                                     â”‚
â”‚   "progress_summary":               â”‚
â”‚     "Moved forward 3x toward door"  â”‚
â”‚ }                                   â”‚
â”‚                                     â”‚
â”‚ â†’ Execute:                          â”‚
â”‚   â€¢ Move 0.25m forward              â”‚
â”‚   â€¢ Update position                 â”‚
â”‚   â€¢ Update trajectory (orange line) â”‚
â”‚   â€¢ Detect new objects              â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å…³é”®æœºåˆ¶è¯´æ˜

### ğŸ¯ Dynamic Landmark System

```
Sub-task 1:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Output:                         â”‚
â”‚   subtask_landmark = "door"         â”‚
â”‚                                     â”‚
â”‚ System Update:                      â”‚
â”‚   landmark_classes = ["door"]       â”‚
â”‚                                     â”‚
â”‚ Map Display:                        â”‚
â”‚   [MAP with purple "door" markers]  â”‚
â”‚   [Orange trajectory to door]       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼ (Sub-task completes)
                  â”‚
                mapper.clear_trajectory()
                  â”‚
                  â–¼
Sub-task 2:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Output:                         â”‚
â”‚   subtask_landmark = "sofa"         â”‚
â”‚                                     â”‚
â”‚ System Update:                      â”‚
â”‚   landmark_classes = ["sofa"]       â”‚
â”‚   (Replaces "door")                 â”‚
â”‚                                     â”‚
â”‚ Map Display:                        â”‚
â”‚   [MAP with purple "sofa" markers]  â”‚
â”‚   [New orange trajectory to sofa]   â”‚
â”‚   [Previous trajectory cleared]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ—ºï¸ Map Rendering Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Base Map (full_map)               â”‚
â”‚   â€¢ Permanent storage               â”‚
â”‚   â€¢ Accumulates ALL detections      â”‚
â”‚   â€¢ Never cleared                   â”‚
â”‚   â€¢ 480Ã—480 semantic grid           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ Copy for display
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Display Map                       â”‚
â”‚   (global_map_with_trajectory)      â”‚
â”‚                                     â”‚
â”‚   = Base Map                        â”‚
â”‚     + Orange trajectory (dynamic)   â”‚
â”‚     + Purple landmarks (filtered)   â”‚
â”‚     + Red agent marker              â”‚
â”‚     + Blue FOV semicircle           â”‚
â”‚                                     â”‚
â”‚   â€¢ Updated every step              â”‚
â”‚   â€¢ Saved to results/               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ 360Â° Panorama Scan

```
Starting Orientation: 0Â° (Front)

Step  0: â”€â–º  Capture "Front (0Â°)"
Step  1: â†‘
Step  2: â†‘   (TURN_LEFT 30Â° each step)
Step  3: â”€â–º  Capture "Left (90Â°)"
Step  4: â†‘
Step  5: â†‘
Step  6: â”€â–º  Capture "Back (180Â°)"
Step  7: â†‘
Step  8: â†‘
Step  9: â”€â–º  Capture "Right (270Â°)"
Step 10: â†‘
Step 11: â†‘

Complete 360Â° rotation (12 Ã— 30Â° = 360Â°)

During each step:
  â€¢ Capture RGB image
  â€¢ Run GroundedSAM detection
  â€¢ Update semantic map
  â€¢ Record detected object classes
  â€¢ Update detected_classes set
```

---

## æ€§èƒ½æŒ‡æ ‡

### Tokenæ¶ˆè€— (GPT-4o)

| Module | Tokens/Call | Calls/Episode | Total Tokens |
|--------|-------------|---------------|--------------|
| LLM Planning | ~2000 | 5-10 | 10k-20k |
| VLM Action | ~1200 | 40-80 | 48k-96k |
| **Total** | - | **45-90** | **58k-116k** |

**Cost Estimate**: $0.01-0.05 per episode (GPT-4o pricing)

### è¿è¡Œæ—¶é—´

| Phase | Time | Notes |
|-------|------|-------|
| 360Â° Scan | ~6s | 12 steps Ã— 0.5s |
| LLM Planning | 2-5s | API call + processing |
| VLM Action | 1-3s | API call + execution |
| Detection | 0.3-0.5s | Per frame (GroundedSAM) |
| **Avg Episode** | **5-10 min** | 50-100 total actions |

### å‡†ç¡®ç‡é¢„æœŸ

| Metric | Performance | Notes |
|--------|-------------|-------|
| Sub-task Completion | ~85-95% | Depends on instruction clarity |
| Collision Avoidance | ~95%+ | Local map guidance |
| Final Goal Success | ~70-80% | Cumulative errors |

---

## éƒ¨ç½²æ£€æŸ¥æ¸…å•

- [ ] **ç¯å¢ƒé…ç½®**
  - [ ] Python 3.8 installed
  - [ ] CUDA 11.1+ available
  - [ ] Habitat-Sim v0.1.7 installed
  - [ ] Habitat-Lab v0.1.7 installed

- [ ] **APIé…ç½®**
  - [ ] `llm_config.yaml` created with valid API key
  - [ ] `vlm_config.yaml` created with valid API key
  - [ ] API connectivity tested

- [ ] **æ¨¡å‹æƒé‡**
  - [ ] GroundingDINO weights downloaded
  - [ ] SAM weights downloaded
  - [ ] Weights in `vlnce_baselines/detection/models/`

- [ ] **æ•°æ®é›†**
  - [ ] Matterport3D scenes downloaded
  - [ ] R2R-CE dataset downloaded
  - [ ] Paths configured in config files

- [ ] **è¾“å‡ºç›®å½•**
  - [ ] `results/` directory exists and writable
  - [ ] Sufficient disk space (>10GB recommended)

- [ ] **æµ‹è¯•è¿è¡Œ**
  - [ ] Single episode test passed
  - [ ] Logs show no errors
  - [ ] Visualizations generated correctly

---

**å‡†å¤‡å°±ç»ªåå³å¯æ¨é€åˆ°æ–°ä»“åº“ï¼** ğŸš€
